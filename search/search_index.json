{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Data Analytics as a Service Data Analytics as a Service for the Government of Canada and external collaborators. Presentations We highly encourage you to watch our YouTube presentation given at Stratosphere: YouTube SlideDeck Security A discussion about some of the security best practices in use by this platform: aaw-security-proposal Advanced Analytics Workspace The following is a list of all the general related repositories for the Advanced Analytics Workspace project. Repository Description Visibility aaw-argocd-applications ArgoCD Applications Private aaw-argocd-manifests Manifests used for ArgoCD deployments Public aaw-argoflow-azure Kubeflow deployment powered by ArgoCD Public aaw-contrib-containers Containers to be used for general purpose Data Science Public aaw-contrib-jupyter-notebooks Containers built to be used with Kubeflow for Data Science Public aaw-contrib-r-notebooks R Notebooks to be used with Advanced Analytics Workspace platform Public aaw-gatekeeper-constraints Gatekeeper constraints built specifically for AAW Private aaw-goofys-injector Mount an S3 bucket, Data Lake, Blob Storage as a file system in a Notebook Public aaw-inferenceservices-controller Kubernetes controller for managing inference services Public aaw-kubeflow-manifest Kustomize installation manifests for Kubeflow Public aaw-kubeflow-controller Kubeflow controller which sets PodDefaults + Vault policies for each Profile detected Public aaw-kubeflow-mlops Kubeflow MLOps pipeline using GitHub Actions Public aaw-kubeflow-opa-sync Synchronize profile editors into the Open Policy Agent for use in MinIO Access Control Public aaw-kubeflow-pipelines-secret-scanner Scan all Kubeflow pipelines for exposed secrets Public aaw-kubeflow-profiles Kubeflow profile manifests stored in YAML Private aaw-kubeflow-profiles-controller Kubeflow profiles controller which allows for custom configuration for an individual profile Public aaw-minio-credential-injector Mutating webhook which adds minio credential annotations to notebook pods Public aaw-network-policies Kubernetes network policies for AAW Private aaw-prob-notebook-controller Kubernetes controller for managing Authorization Policies associated to Protected-B Notebooks Public aaw-security-proposal Proposal for the implementation of Protected B workloads in AAW Public aaw-toleration-injector Kubernetes toleration injector with support for GPUs and Node Pools Public Terraform The following is a list of all the terraform related repositories for the Advanced Analytics Workspace project. Repository Description Visibility terraform-aaw-managed-databases Terraform to deploy Azure Managed Databases Private terraform-aaw-vault Terraform for configuring Hashicorp Vault Private terraform-advanced-analytics-workspaces-infrastructure Terraform to deploy the infrastructure for the Advanced Analytics Workspaces Private terraform-aaw-infrastructure-aaw-dev-cc-00 Terraform to deploy the AAW infrastructure for the development environment Private terraform-aaw-infrastructure-aaw-prod-cc-00 Terraform to deploy the AAW infrastructure for the production environment Private Community Engagement The following is a list of some of the collaborative work we made available to improve upstream projects. Repository Description Visibility boathouse Manage Kubernetes storage mounts with Goofys Public jupyter-apis Golang replacement for the Kubeflow Jupyter Web APIs Public jupyterlab-language-pack-fr_FR JupyterLab fr-FR Language Pack Public vault-plugin-secrets-minio Vault plugin which will provision multi-user keys for Minio Public The following is a list of some of the forked projects where we have provided multilingual support and other UX related enhancements. Repository Description Visibility kubeflow Multilingual support for Kubeflow Public kubeflow-pipelines Multilingual support for Kubeflow Pipelines Public minio Multilingual support for MinIO Public minio-console Multilingual support for MinIO Console Public rstudio Multilingual support for RStudio Public (Fran\u00e7ais) AAW ArgoCD Manifests How to Contribute See CONTRIBUTING.md License Unless otherwise noted, the source code of this project is covered under Crown Copyright, Government of Canada, and is distributed under the MIT License . The Canada wordmark and related graphics associated with this distribution are protected under trademark law and copyright law. No permission is granted to use them outside the parameters of the Government of Canada's corporate identity program. For more information, see Federal identity requirements . Le nom du projet Quel est ce projet? Comment \u00e7a marche? Qui utilisera ce projet? Quel est le but de ce projet? Comment contribuer Voir CONTRIBUTING.md Licence Sauf indication contraire, le code source de ce projet est prot\u00e9g\u00e9 par le droit d'auteur de la Couronne du gouvernement du Canada et distribu\u00e9 sous la licence MIT . Le mot-symbole \u00ab Canada \u00bb et les \u00e9l\u00e9ments graphiques connexes li\u00e9s \u00e0 cette distribution sont prot\u00e9g\u00e9s en vertu des lois portant sur les marques de commerce et le droit d'auteur. Aucune autorisation n'est accord\u00e9e pour leur utilisation \u00e0 l'ext\u00e9rieur des param\u00e8tres du programme de coordination de l'image de marque du gouvernement du Canada. Pour obtenir davantage de renseignements \u00e0 ce sujet, veuillez consulter les Exigences pour l'image de marque .","title":"Home"},{"location":"#data-analytics-as-a-service","text":"Data Analytics as a Service for the Government of Canada and external collaborators.","title":"Data Analytics as a Service"},{"location":"#presentations","text":"We highly encourage you to watch our YouTube presentation given at Stratosphere: YouTube SlideDeck","title":"Presentations"},{"location":"#security","text":"A discussion about some of the security best practices in use by this platform: aaw-security-proposal","title":"Security"},{"location":"#advanced-analytics-workspace","text":"The following is a list of all the general related repositories for the Advanced Analytics Workspace project. Repository Description Visibility aaw-argocd-applications ArgoCD Applications Private aaw-argocd-manifests Manifests used for ArgoCD deployments Public aaw-argoflow-azure Kubeflow deployment powered by ArgoCD Public aaw-contrib-containers Containers to be used for general purpose Data Science Public aaw-contrib-jupyter-notebooks Containers built to be used with Kubeflow for Data Science Public aaw-contrib-r-notebooks R Notebooks to be used with Advanced Analytics Workspace platform Public aaw-gatekeeper-constraints Gatekeeper constraints built specifically for AAW Private aaw-goofys-injector Mount an S3 bucket, Data Lake, Blob Storage as a file system in a Notebook Public aaw-inferenceservices-controller Kubernetes controller for managing inference services Public aaw-kubeflow-manifest Kustomize installation manifests for Kubeflow Public aaw-kubeflow-controller Kubeflow controller which sets PodDefaults + Vault policies for each Profile detected Public aaw-kubeflow-mlops Kubeflow MLOps pipeline using GitHub Actions Public aaw-kubeflow-opa-sync Synchronize profile editors into the Open Policy Agent for use in MinIO Access Control Public aaw-kubeflow-pipelines-secret-scanner Scan all Kubeflow pipelines for exposed secrets Public aaw-kubeflow-profiles Kubeflow profile manifests stored in YAML Private aaw-kubeflow-profiles-controller Kubeflow profiles controller which allows for custom configuration for an individual profile Public aaw-minio-credential-injector Mutating webhook which adds minio credential annotations to notebook pods Public aaw-network-policies Kubernetes network policies for AAW Private aaw-prob-notebook-controller Kubernetes controller for managing Authorization Policies associated to Protected-B Notebooks Public aaw-security-proposal Proposal for the implementation of Protected B workloads in AAW Public aaw-toleration-injector Kubernetes toleration injector with support for GPUs and Node Pools Public","title":"Advanced Analytics Workspace"},{"location":"#terraform","text":"The following is a list of all the terraform related repositories for the Advanced Analytics Workspace project. Repository Description Visibility terraform-aaw-managed-databases Terraform to deploy Azure Managed Databases Private terraform-aaw-vault Terraform for configuring Hashicorp Vault Private terraform-advanced-analytics-workspaces-infrastructure Terraform to deploy the infrastructure for the Advanced Analytics Workspaces Private terraform-aaw-infrastructure-aaw-dev-cc-00 Terraform to deploy the AAW infrastructure for the development environment Private terraform-aaw-infrastructure-aaw-prod-cc-00 Terraform to deploy the AAW infrastructure for the production environment Private","title":"Terraform"},{"location":"#community-engagement","text":"The following is a list of some of the collaborative work we made available to improve upstream projects. Repository Description Visibility boathouse Manage Kubernetes storage mounts with Goofys Public jupyter-apis Golang replacement for the Kubeflow Jupyter Web APIs Public jupyterlab-language-pack-fr_FR JupyterLab fr-FR Language Pack Public vault-plugin-secrets-minio Vault plugin which will provision multi-user keys for Minio Public The following is a list of some of the forked projects where we have provided multilingual support and other UX related enhancements. Repository Description Visibility kubeflow Multilingual support for Kubeflow Public kubeflow-pipelines Multilingual support for Kubeflow Pipelines Public minio Multilingual support for MinIO Public minio-console Multilingual support for MinIO Console Public rstudio Multilingual support for RStudio Public (Fran\u00e7ais)","title":"Community Engagement"},{"location":"#aaw-argocd-manifests","text":"","title":"AAW ArgoCD Manifests"},{"location":"#how-to-contribute","text":"See CONTRIBUTING.md","title":"How to Contribute"},{"location":"#license","text":"Unless otherwise noted, the source code of this project is covered under Crown Copyright, Government of Canada, and is distributed under the MIT License . The Canada wordmark and related graphics associated with this distribution are protected under trademark law and copyright law. No permission is granted to use them outside the parameters of the Government of Canada's corporate identity program. For more information, see Federal identity requirements .","title":"License"},{"location":"#le-nom-du-projet","text":"Quel est ce projet? Comment \u00e7a marche? Qui utilisera ce projet? Quel est le but de ce projet?","title":"Le nom du projet"},{"location":"#comment-contribuer","text":"Voir CONTRIBUTING.md","title":"Comment contribuer"},{"location":"#licence","text":"Sauf indication contraire, le code source de ce projet est prot\u00e9g\u00e9 par le droit d'auteur de la Couronne du gouvernement du Canada et distribu\u00e9 sous la licence MIT . Le mot-symbole \u00ab Canada \u00bb et les \u00e9l\u00e9ments graphiques connexes li\u00e9s \u00e0 cette distribution sont prot\u00e9g\u00e9s en vertu des lois portant sur les marques de commerce et le droit d'auteur. Aucune autorisation n'est accord\u00e9e pour leur utilisation \u00e0 l'ext\u00e9rieur des param\u00e8tres du programme de coordination de l'image de marque du gouvernement du Canada. Pour obtenir davantage de renseignements \u00e0 ce sujet, veuillez consulter les Exigences pour l'image de marque .","title":"Licence"},{"location":"architecture/00-introduction/","text":"\\begin{center}UNCLASSIFIED / NON-CLASSIFI\u00c9\\end{center} \\begin{center}\\textbf{FINAL DRAFT: v1.0.0-rc1}\\end{center} \\newpage Introduction Background The Advanced Analytics Workspaces (AAW) was launched in response to the COVID-19 pandemic which caused a shift in work environment for Statistics Canada employees. AAW was tasked with providing an unclassified compute environment to allow for data scientists to perform analysis work using a public cloud compute environment without requiring access to Statistics Canada networks and issued devices. Statistics Canada is now interested in expanding the environment to include Protected B data. This requires modification to the environment to enable the necessary isolation and exfiltration protections. The platform was built as a collaboration between: Cloud Workload and Migration Division Data Analytics as a Service Division Data Science Division Technology The Advanced Analytics Workspaces is constructed of many tools. Its base is built on Kubernetes, Cloud Native Computing Foundation (CNCF) tooling, and Kubeflow. The platform is made up of many different open-source software components. In addition, some custom components have also been developed to provide desired functionality. Everything is running with an Azure Kubernetes Service (AKS) cluster. Kubernetes is an extensible orchestration system and is a platform for building platforms. Components of the platform include, generally, components which either provide functionality to end users or components which ensure the security of the platform. This proposal will focus on the following components of Kubernetes and platform components to provide an isolated Protected B compute environment: Azure-level resources Kubernetes Storage policies Network policies Istio Service Mesh Fluentd / Elasticsearch MinIO Further, this proposal will discuss securing the Kubeflow component to provide users with the appropriate environment for running Protected B data analysis: Kubeflow Notebook Servers Remote Desktop Kubeflow Pipelines This proposal attempts to strike a balance between security requirements and user freedom. This proposal was created by Zachary Seguin, with the assistance of William Hearn, Justin Bertrand, Brendan Gadd, Andrew Scribner, Blair Drummond and Charles B\u00e9lisle. Any questions should be directed to zachary.seguin@canada.ca . Disclaimer Many of the recommendations of this document are intended to align with the best practicies of the industry, as well as the security requirements specified in ITSG-22/ITSG-33. However, no explicit mapping excercise was performed between the ITSG-22/ITSG-33 controls and this proposal. Reporting a security issue If you identify an issue with the Advanced Analytics Workspaces environment or with this security proposal, then please send an email (encrypted, if possible) to brendan.gadd@canada.ca , william.hearn@canada.ca , and zachary.seguin@canada.ca .","title":"Securing Advanced Analytics Workspaces"},{"location":"architecture/00-introduction/#introduction","text":"","title":"Introduction"},{"location":"architecture/00-introduction/#background","text":"The Advanced Analytics Workspaces (AAW) was launched in response to the COVID-19 pandemic which caused a shift in work environment for Statistics Canada employees. AAW was tasked with providing an unclassified compute environment to allow for data scientists to perform analysis work using a public cloud compute environment without requiring access to Statistics Canada networks and issued devices. Statistics Canada is now interested in expanding the environment to include Protected B data. This requires modification to the environment to enable the necessary isolation and exfiltration protections. The platform was built as a collaboration between: Cloud Workload and Migration Division Data Analytics as a Service Division Data Science Division","title":"Background"},{"location":"architecture/00-introduction/#technology","text":"The Advanced Analytics Workspaces is constructed of many tools. Its base is built on Kubernetes, Cloud Native Computing Foundation (CNCF) tooling, and Kubeflow. The platform is made up of many different open-source software components. In addition, some custom components have also been developed to provide desired functionality. Everything is running with an Azure Kubernetes Service (AKS) cluster. Kubernetes is an extensible orchestration system and is a platform for building platforms. Components of the platform include, generally, components which either provide functionality to end users or components which ensure the security of the platform. This proposal will focus on the following components of Kubernetes and platform components to provide an isolated Protected B compute environment: Azure-level resources Kubernetes Storage policies Network policies Istio Service Mesh Fluentd / Elasticsearch MinIO Further, this proposal will discuss securing the Kubeflow component to provide users with the appropriate environment for running Protected B data analysis: Kubeflow Notebook Servers Remote Desktop Kubeflow Pipelines This proposal attempts to strike a balance between security requirements and user freedom. This proposal was created by Zachary Seguin, with the assistance of William Hearn, Justin Bertrand, Brendan Gadd, Andrew Scribner, Blair Drummond and Charles B\u00e9lisle. Any questions should be directed to zachary.seguin@canada.ca .","title":"Technology"},{"location":"architecture/00-introduction/#disclaimer","text":"Many of the recommendations of this document are intended to align with the best practicies of the industry, as well as the security requirements specified in ITSG-22/ITSG-33. However, no explicit mapping excercise was performed between the ITSG-22/ITSG-33 controls and this proposal.","title":"Disclaimer"},{"location":"architecture/00-introduction/#reporting-a-security-issue","text":"If you identify an issue with the Advanced Analytics Workspaces environment or with this security proposal, then please send an email (encrypted, if possible) to brendan.gadd@canada.ca , william.hearn@canada.ca , and zachary.seguin@canada.ca .","title":"Reporting a security issue"},{"location":"architecture/01-limitations/","text":"Limitations During the preparation of a security design for enabling Protected B workloads in the existing Advanced Analytics Workspaces (AAW), it was determined that while not unfeasible to integrate them in the existing environment, a more secure AAW environment could be re-constructed to provide the appropriate levels of defence, including providing better workload isolation between levels of data classification. Options Two options were identified on how to design the Protected B workloads: Use two separate clusters: 1 Unclassified, 1 Protected B Use one cluster, with isolation While the first option provides the highest level of security, there are major tradeoffs in relation to user experience and maintainability. Therefore it was decided that the best balance between security and usability/maintainability was provided by option 2. Therefore, this proposal describes the use of one cluster for both Unclassified and Protected B workloads. Development requirements Some of the recommendations in this document may require some custom development of control components in order to implement the recommendation. \\newpage","title":"Limitations"},{"location":"architecture/01-limitations/#limitations","text":"During the preparation of a security design for enabling Protected B workloads in the existing Advanced Analytics Workspaces (AAW), it was determined that while not unfeasible to integrate them in the existing environment, a more secure AAW environment could be re-constructed to provide the appropriate levels of defence, including providing better workload isolation between levels of data classification.","title":"Limitations"},{"location":"architecture/01-limitations/#options","text":"Two options were identified on how to design the Protected B workloads: Use two separate clusters: 1 Unclassified, 1 Protected B Use one cluster, with isolation While the first option provides the highest level of security, there are major tradeoffs in relation to user experience and maintainability. Therefore it was decided that the best balance between security and usability/maintainability was provided by option 2. Therefore, this proposal describes the use of one cluster for both Unclassified and Protected B workloads.","title":"Options"},{"location":"architecture/01-limitations/#development-requirements","text":"Some of the recommendations in this document may require some custom development of control components in order to implement the recommendation. \\newpage","title":"Development requirements"},{"location":"architecture/02-azure/","text":"Azure Resources The Advanced Analytics Workspaces (AAW) runs within the Azure Cloud environment. Thus, it's critical that the Azure resources be correctly configured to provide a secure context for the AAW and its associated Protected B workloads. This section discusses the proposed implementation of these Azure resources. Simply put, the following diagram depicts the overall layout of the Azure resources (based on network configuration): Let's deep dive down to the difference resources and how they are proposed to be configured. Subscription Currently, the AAW environment lives in the vdl subscription. As it stands, there are many person and non-person entities who have full access to resources within the subscription ( Owner or Contributor at the subscription level), many of whom are not related to or associated with the AAW project. This provides a high level of risk of many accidental or unauthorized activities within the environment, including: Accidental or malicious removal of resources Accidental or malicious removal of security policies Malicious access to unauthorized resources While generally users with access to the environment are trusted by the organization, most users do not have a need to have this access within the AAW environment. Therefore, this is directly in violation of the principle of least privilege. Recommendation AZ-SUB-01 : The AAW be moved to its own subscription with limited person and non-person entities who have Owner or Contributor at the subscription level. Resource groups Recommendation AZ-RG-01 : The following resource groups be created with the defined purpose: aaw-$env-$region-$num-rg-network : Network resources (VNET, Firewall) aaw-$env-$region-$num-rg-aks : AKS resources (AKS, Container Registry) aaw-$env-$region-$num-rg-aks-managed : AKS managed resources for each cluster aaw-$env-$region-$num-rg-backup : Backup resources (Velero) aaw-$env-$region-$num-rg-security : Security resources (e.g. Vault KeyVault, Storage Account) aaw-$env-$region-$num-rg-data : Data resources (e.g. Databases) (see below for variable values) Resource naming Recommendation AZ-RN-01 : The naming convention of Azure resources be: aaw-$env-$region-$num-$type-$purpose , where: Field Value $type The resource type, usually abbreviated $region The region of the resource, if region-specific. Usually cc , for Canada Central $num The instance number of AAW in that env/region, starting at 00 $env The environment of the resource, usually prod or dev $purpose If multiple resources of this type are deployed in this env/region/num, then the purpose of the resource should be appended at end Common Azure resources and their abbreviations: Abbreviation Resource rg Resource group vnet Virtual network snet Subnet rt Route table fw Firewall aks Azure Kubernetes Service cr Container Registry sa Storage account msi User assigned managed self identity kv Azure Key Vault Example resource names: aaw-prod-cc-00-vnet-hub : the hub vnet in the aaw-prod-cc-00 environment aaw-prod-cc-00-aks : the AKS cluster in Canada Central in the aaw-prod-cc-00 environment Where resources do not support - in the name, then the - should be omitted from the resource name. Networking A proper network layout will enable the AAW environment to apply appropriate rules and restrictions to workloads based on the source and destination of each connection. Recommendation AZ-NW-01 : Each region and environment will be assigned a network space of /14, broken down into the following Virtual Networks: Hub VNET (/16) AKS VNET (/16) Data VNET (/16) Reserved for future use (/16) A VNET is best given a /16 (65536) of IP space as this is the maximum number of private IPs permitted in a virtual network: https://docs.microsoft.com/en-us/azure/azure-resource-manager/management/azure-subscription-service-limits#networking-limits . This recommendation is referred to as a Hub & Spoke model. This allows us to maximize the available IP space for the AKS cluster within the AKS VNET. While this incurrs additional peering costs between the VNETs it is offset but the increased security posture - in particular if the AAW environment is peered with other enviroments in the future, as traffic can be forced through the Azure firewall first. Note: The Data VNET / subnets are generally not needed as we can use Service Endpoints for managed databases and storage accounts. Recommendation AZ-NW-02 : Each virtual network be broken down into the following subnets: HUB VNET Network Subnet Start IP End IP Number of IPs firewall x.y.255.192/26 x.y.255.192 x.y.255.255 64 AKS VNET Network Subnet Start IP End IP Number of IPs load-balancers x.y.254.0/23 x.y.254.0 x.y.255.255 512 system x.y.0.0/18 x.y.0.0 x.y.63.255 16384 user-unclassified x.y.64.0/18 x.y.64.0 x.y.127.255 16384 user-protected-b x.y.128.0/18 x.y.128.0 x.y.191.255 16384 DATA VNET Network Subnet Start IP End IP Number of IPs data-unclassified x.y.0.0/22 x.y.0.0 x.y.3.255 1024 data-protected-b x.y.4.0/22 x.y.4.0 x.y.7.255 1024 Firewall Azure Firewall The Azure Firewall sits at the edge of the AAW environment and serves as the last defence between the internal networks and the general internet. Recommendation AZ-FW-01 : The Azure Firewall be used at the edge of the AAW networks. Recommendation AZ-FW-02 : The Azure Firewall be configured with the following rules: Inbound traffic destined for an internal subnet shall be permitted to a Load Balancer located in the load-balancers subnet. Outbound traffic from the system , user-protected-b , data-unclassified and data-protected-b subnets be restricted to essential traffic only, with policies unique to each subnet. Outbound traffic to ports 80/443, and others as needed, be permitted from the user-unclassified subnet. Traffic from user-unclassified be permitted to data-unclassified , and the same be applied for protected-b . Network Security Groups (NSGs) The Azure Firewall provides protection between external networks and the Advanced Analytics Environment, but does not provide protection for traffic flows within the environment. Azure provides a Network Security Group (NSG) feature that allows the control of traffic between subnets in a Virtual Network. Recommendation AZ-FW-03 : Network Security Groups (NSGs) be used to control inter-subnet traffic flows within the same VNET. Recommendation AZ-FW-04 : Network Security Groups (NSGs) be configured as: load-balancers may accept traffic from any subnet. Restricting access to load balancers is done on a per-subnet outbound restriction. system subnet can accept any traffic to and from the user-* subnets. user-* subnets can accept any traffic to/from the system subnet, but not between user subnets. These subnets may also access the matching data-* subnet. Disk storage Disk encryption at rest is provided by Microsoft out of the box. By default, however, these encryption keys come from Microsoft. For increased security of protected data, it is recommended that Customer Managed Keys be utilized. Note, however, that not all Azure services support customer managed keys. The use of Customer Managed Keys is recommended by the Center for Internet Security (CIS) for storing sensitive data, as well as the ITSG-33 controls SC-28 (PROTECTION OF INFORMATION AT REST) and SC-12 (CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT). Recommendation AZ-STR-01 : Customer Managed Keys be utlized where possible within the Azure environment. Recommendation AZ-STR-02 : The Azure Key Vault key for storage encryption be backed by a Hardware Security Module (HSM). There are two options: Shared HSM: $1.28/key/month + $0.039/10000 transactions Single-tenant HSM: $6.208/hour (~$4,600/month) Automatic key rotation should be configured for storage encryption keys, assuming this is available for all services. If it is not, then manual rotation should occur every 90 days (3 months). Azure Kubernetes Service (AKS) With the foundational Azure configuration and network configuration, we can now build the Azure Kubernetes Service (AKS) cluster for the Advanced Analytics Workspaces environment. All the functionality discussed above was designed with the understand of what features are supported and not supported by the Azure Kubernetes Service. Therefore, the following recommendations are based on the base Azure concepts presented above. Recommendation AZ-AKS-01 : The AAW Kubernetes cluster would be constructed with the following node pools: Pool VM Type Subnet Purpose system Standard_D16s_v3 system Running system components of the AAW environment monitoring Standard_E16s_v3 system Logging and monitoring components of the AAW environment storage Standard_D32s_v3 system Storage components of the AAW environment user-unclassified Standard_D16s_v3 user-unclassified Unclassified user workloads user-gpu-unclassified Standard_NC6s_v3 user-unclassified Unclassified user GPU workloads user-protected-b Standard_D16s_v3 user-protected-b Protected B user workloads user-gpu-protected-b Standard_NC6s_v3 user-protected-b Protected B user GPU workloads The cluster be constructed with the following features enabled: User defined routing Azure Active Directory authentication Control Plane Managed Identity Customer Managed Keys for disk encryption The best practices in protecting the AKS cluster is to secure access to the control plane of Kubernetes. The best way to do this is by running a fully private AKS cluster (using Private Link). Unfortunately, due to reliance on external tooling such as GitHub Actions, this is not possible. Therefore, the next best option is to apply firewalls protecting the control plane. Recommendation AZ-AKS-02 : Apply control plane firewall which restricts access to Statistics Canada networks only. Recommendation AZ-AKS-03 : To manage the Kubernetes cluster from GitHub Actions, a self-hosted runner should be deployed and utilized so that access to the API server can be kept limited. Infrastructure as Code Recommendation KUBE-CAC-01 : All Azure resources deployed to the Advanced Analytics Workspaces environment be managed via Terraform, a Infrastructure as Code tool. The only resource exempt from this requirement is the Subscription.","title":"Azure Resources"},{"location":"architecture/02-azure/#azure-resources","text":"The Advanced Analytics Workspaces (AAW) runs within the Azure Cloud environment. Thus, it's critical that the Azure resources be correctly configured to provide a secure context for the AAW and its associated Protected B workloads. This section discusses the proposed implementation of these Azure resources. Simply put, the following diagram depicts the overall layout of the Azure resources (based on network configuration): Let's deep dive down to the difference resources and how they are proposed to be configured.","title":"Azure Resources"},{"location":"architecture/02-azure/#subscription","text":"Currently, the AAW environment lives in the vdl subscription. As it stands, there are many person and non-person entities who have full access to resources within the subscription ( Owner or Contributor at the subscription level), many of whom are not related to or associated with the AAW project. This provides a high level of risk of many accidental or unauthorized activities within the environment, including: Accidental or malicious removal of resources Accidental or malicious removal of security policies Malicious access to unauthorized resources While generally users with access to the environment are trusted by the organization, most users do not have a need to have this access within the AAW environment. Therefore, this is directly in violation of the principle of least privilege. Recommendation AZ-SUB-01 : The AAW be moved to its own subscription with limited person and non-person entities who have Owner or Contributor at the subscription level.","title":"Subscription"},{"location":"architecture/02-azure/#resource-groups","text":"Recommendation AZ-RG-01 : The following resource groups be created with the defined purpose: aaw-$env-$region-$num-rg-network : Network resources (VNET, Firewall) aaw-$env-$region-$num-rg-aks : AKS resources (AKS, Container Registry) aaw-$env-$region-$num-rg-aks-managed : AKS managed resources for each cluster aaw-$env-$region-$num-rg-backup : Backup resources (Velero) aaw-$env-$region-$num-rg-security : Security resources (e.g. Vault KeyVault, Storage Account) aaw-$env-$region-$num-rg-data : Data resources (e.g. Databases) (see below for variable values)","title":"Resource groups"},{"location":"architecture/02-azure/#resource-naming","text":"Recommendation AZ-RN-01 : The naming convention of Azure resources be: aaw-$env-$region-$num-$type-$purpose , where: Field Value $type The resource type, usually abbreviated $region The region of the resource, if region-specific. Usually cc , for Canada Central $num The instance number of AAW in that env/region, starting at 00 $env The environment of the resource, usually prod or dev $purpose If multiple resources of this type are deployed in this env/region/num, then the purpose of the resource should be appended at end Common Azure resources and their abbreviations: Abbreviation Resource rg Resource group vnet Virtual network snet Subnet rt Route table fw Firewall aks Azure Kubernetes Service cr Container Registry sa Storage account msi User assigned managed self identity kv Azure Key Vault Example resource names: aaw-prod-cc-00-vnet-hub : the hub vnet in the aaw-prod-cc-00 environment aaw-prod-cc-00-aks : the AKS cluster in Canada Central in the aaw-prod-cc-00 environment Where resources do not support - in the name, then the - should be omitted from the resource name.","title":"Resource naming"},{"location":"architecture/02-azure/#networking","text":"A proper network layout will enable the AAW environment to apply appropriate rules and restrictions to workloads based on the source and destination of each connection. Recommendation AZ-NW-01 : Each region and environment will be assigned a network space of /14, broken down into the following Virtual Networks: Hub VNET (/16) AKS VNET (/16) Data VNET (/16) Reserved for future use (/16) A VNET is best given a /16 (65536) of IP space as this is the maximum number of private IPs permitted in a virtual network: https://docs.microsoft.com/en-us/azure/azure-resource-manager/management/azure-subscription-service-limits#networking-limits . This recommendation is referred to as a Hub & Spoke model. This allows us to maximize the available IP space for the AKS cluster within the AKS VNET. While this incurrs additional peering costs between the VNETs it is offset but the increased security posture - in particular if the AAW environment is peered with other enviroments in the future, as traffic can be forced through the Azure firewall first. Note: The Data VNET / subnets are generally not needed as we can use Service Endpoints for managed databases and storage accounts. Recommendation AZ-NW-02 : Each virtual network be broken down into the following subnets: HUB VNET Network Subnet Start IP End IP Number of IPs firewall x.y.255.192/26 x.y.255.192 x.y.255.255 64 AKS VNET Network Subnet Start IP End IP Number of IPs load-balancers x.y.254.0/23 x.y.254.0 x.y.255.255 512 system x.y.0.0/18 x.y.0.0 x.y.63.255 16384 user-unclassified x.y.64.0/18 x.y.64.0 x.y.127.255 16384 user-protected-b x.y.128.0/18 x.y.128.0 x.y.191.255 16384 DATA VNET Network Subnet Start IP End IP Number of IPs data-unclassified x.y.0.0/22 x.y.0.0 x.y.3.255 1024 data-protected-b x.y.4.0/22 x.y.4.0 x.y.7.255 1024","title":"Networking"},{"location":"architecture/02-azure/#firewall","text":"","title":"Firewall"},{"location":"architecture/02-azure/#azure-firewall","text":"The Azure Firewall sits at the edge of the AAW environment and serves as the last defence between the internal networks and the general internet. Recommendation AZ-FW-01 : The Azure Firewall be used at the edge of the AAW networks. Recommendation AZ-FW-02 : The Azure Firewall be configured with the following rules: Inbound traffic destined for an internal subnet shall be permitted to a Load Balancer located in the load-balancers subnet. Outbound traffic from the system , user-protected-b , data-unclassified and data-protected-b subnets be restricted to essential traffic only, with policies unique to each subnet. Outbound traffic to ports 80/443, and others as needed, be permitted from the user-unclassified subnet. Traffic from user-unclassified be permitted to data-unclassified , and the same be applied for protected-b .","title":"Azure Firewall"},{"location":"architecture/02-azure/#network-security-groups-nsgs","text":"The Azure Firewall provides protection between external networks and the Advanced Analytics Environment, but does not provide protection for traffic flows within the environment. Azure provides a Network Security Group (NSG) feature that allows the control of traffic between subnets in a Virtual Network. Recommendation AZ-FW-03 : Network Security Groups (NSGs) be used to control inter-subnet traffic flows within the same VNET. Recommendation AZ-FW-04 : Network Security Groups (NSGs) be configured as: load-balancers may accept traffic from any subnet. Restricting access to load balancers is done on a per-subnet outbound restriction. system subnet can accept any traffic to and from the user-* subnets. user-* subnets can accept any traffic to/from the system subnet, but not between user subnets. These subnets may also access the matching data-* subnet.","title":"Network Security Groups (NSGs)"},{"location":"architecture/02-azure/#disk-storage","text":"Disk encryption at rest is provided by Microsoft out of the box. By default, however, these encryption keys come from Microsoft. For increased security of protected data, it is recommended that Customer Managed Keys be utilized. Note, however, that not all Azure services support customer managed keys. The use of Customer Managed Keys is recommended by the Center for Internet Security (CIS) for storing sensitive data, as well as the ITSG-33 controls SC-28 (PROTECTION OF INFORMATION AT REST) and SC-12 (CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT). Recommendation AZ-STR-01 : Customer Managed Keys be utlized where possible within the Azure environment. Recommendation AZ-STR-02 : The Azure Key Vault key for storage encryption be backed by a Hardware Security Module (HSM). There are two options: Shared HSM: $1.28/key/month + $0.039/10000 transactions Single-tenant HSM: $6.208/hour (~$4,600/month) Automatic key rotation should be configured for storage encryption keys, assuming this is available for all services. If it is not, then manual rotation should occur every 90 days (3 months).","title":"Disk storage"},{"location":"architecture/02-azure/#azure-kubernetes-service-aks","text":"With the foundational Azure configuration and network configuration, we can now build the Azure Kubernetes Service (AKS) cluster for the Advanced Analytics Workspaces environment. All the functionality discussed above was designed with the understand of what features are supported and not supported by the Azure Kubernetes Service. Therefore, the following recommendations are based on the base Azure concepts presented above. Recommendation AZ-AKS-01 : The AAW Kubernetes cluster would be constructed with the following node pools: Pool VM Type Subnet Purpose system Standard_D16s_v3 system Running system components of the AAW environment monitoring Standard_E16s_v3 system Logging and monitoring components of the AAW environment storage Standard_D32s_v3 system Storage components of the AAW environment user-unclassified Standard_D16s_v3 user-unclassified Unclassified user workloads user-gpu-unclassified Standard_NC6s_v3 user-unclassified Unclassified user GPU workloads user-protected-b Standard_D16s_v3 user-protected-b Protected B user workloads user-gpu-protected-b Standard_NC6s_v3 user-protected-b Protected B user GPU workloads The cluster be constructed with the following features enabled: User defined routing Azure Active Directory authentication Control Plane Managed Identity Customer Managed Keys for disk encryption The best practices in protecting the AKS cluster is to secure access to the control plane of Kubernetes. The best way to do this is by running a fully private AKS cluster (using Private Link). Unfortunately, due to reliance on external tooling such as GitHub Actions, this is not possible. Therefore, the next best option is to apply firewalls protecting the control plane. Recommendation AZ-AKS-02 : Apply control plane firewall which restricts access to Statistics Canada networks only. Recommendation AZ-AKS-03 : To manage the Kubernetes cluster from GitHub Actions, a self-hosted runner should be deployed and utilized so that access to the API server can be kept limited.","title":"Azure Kubernetes Service (AKS)"},{"location":"architecture/02-azure/#infrastructure-as-code","text":"Recommendation KUBE-CAC-01 : All Azure resources deployed to the Advanced Analytics Workspaces environment be managed via Terraform, a Infrastructure as Code tool. The only resource exempt from this requirement is the Subscription.","title":"Infrastructure as Code"},{"location":"architecture/03-classification/","text":"Classification Proper identification of workload classifications is critical to providing separation of unclassified and protected workloads within the Advanced Analytics Workspaces. Due to the AAW\u2019s origin in unclassified workloads, the environment will continue to support, and default to, this type of workload. In doing so, it will retain the associated flexibility in tooling, connectivity, etc. This approach provides the lowest friction to users: Existing unclassified workloads will continue to function Workloads that necessitate external connectivity (e.g. web scraping) remain possible Workloads that are explicitly indicated as being Protected will have a series of restrictions placed on them and, in turn, may gain controlled access to Protected resources. A metadata-driven approach to proactive identification of Protected workloads is recommended, implemented using Kubernetes labels. Labels According to the Kubernetes documentation, labels are: key/value pairs that are attached to objects, such as pods. Labels are intended to be used to specify identifying attributes of objects that are meaningful and relevant to users, but do not directly imply semantics to the core system. Labels can be used to organize and to select subsets of objects. Labels can be attached to objects at creation time and subsequently added and modified at any time. Each object can have a set of key/value labels defined. Each Key must be unique for a given object. \u2014 https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/ Recommendation CL-LBL-01 : Use Kubernetes label data.statcan.gc.ca/classification as a basis for tracking the data classification of, and controlling access to, Kubernetes objects. data.statcan.gc.ca/classification The classification label will track the data classification of the labelled object. The classification value on storage-related objects will identify the data classification, whereas the classification on compute-related objects will represent the classification of data that is processed by the object. Only bolded values will be used within the AAW. Value Meaning unclassified Unclassified protected-a Protected A protected-b Protected B protected-c Protected C confidential Confidential secret Secret top-secret Top Secret If the classification label is not provided, then the workload is assumed to be Unclassified. Important note : Labels in Kubernetes are mutable, meaning they can be changed at any time. To prevent security incidents, we must enforce that the data.statcan.gc.ca/classification label be immutable. This will be done through Gatekeeper and the Open Policy Agent. Recommendation CL-LBL-02 : The proposed Kubernetes label data.statcan.gc.ca/classification be made \"immutable\" via Gatekeeper / Open Policy Agent policies.","title":"Classification"},{"location":"architecture/03-classification/#classification","text":"Proper identification of workload classifications is critical to providing separation of unclassified and protected workloads within the Advanced Analytics Workspaces. Due to the AAW\u2019s origin in unclassified workloads, the environment will continue to support, and default to, this type of workload. In doing so, it will retain the associated flexibility in tooling, connectivity, etc. This approach provides the lowest friction to users: Existing unclassified workloads will continue to function Workloads that necessitate external connectivity (e.g. web scraping) remain possible Workloads that are explicitly indicated as being Protected will have a series of restrictions placed on them and, in turn, may gain controlled access to Protected resources. A metadata-driven approach to proactive identification of Protected workloads is recommended, implemented using Kubernetes labels.","title":"Classification"},{"location":"architecture/03-classification/#labels","text":"According to the Kubernetes documentation, labels are: key/value pairs that are attached to objects, such as pods. Labels are intended to be used to specify identifying attributes of objects that are meaningful and relevant to users, but do not directly imply semantics to the core system. Labels can be used to organize and to select subsets of objects. Labels can be attached to objects at creation time and subsequently added and modified at any time. Each object can have a set of key/value labels defined. Each Key must be unique for a given object. \u2014 https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/ Recommendation CL-LBL-01 : Use Kubernetes label data.statcan.gc.ca/classification as a basis for tracking the data classification of, and controlling access to, Kubernetes objects.","title":"Labels"},{"location":"architecture/03-classification/#datastatcangccaclassification","text":"The classification label will track the data classification of the labelled object. The classification value on storage-related objects will identify the data classification, whereas the classification on compute-related objects will represent the classification of data that is processed by the object. Only bolded values will be used within the AAW. Value Meaning unclassified Unclassified protected-a Protected A protected-b Protected B protected-c Protected C confidential Confidential secret Secret top-secret Top Secret If the classification label is not provided, then the workload is assumed to be Unclassified. Important note : Labels in Kubernetes are mutable, meaning they can be changed at any time. To prevent security incidents, we must enforce that the data.statcan.gc.ca/classification label be immutable. This will be done through Gatekeeper and the Open Policy Agent. Recommendation CL-LBL-02 : The proposed Kubernetes label data.statcan.gc.ca/classification be made \"immutable\" via Gatekeeper / Open Policy Agent policies.","title":"data.statcan.gc.ca/classification"},{"location":"architecture/04-storage/","text":"Storage Data is the largest asset and attack surface of Protected B workloads within the Advanced Analytics Workspaces. This section is focusing on storage controlled by users directely. The AAW environment consists currently of two main types of user storage: Disk storage (attached to one pod at a time) Object storage Additionally, data is obtained from the following sources: Object storage (internal to AAW) Statistics Canada public data External data sources Kubernetes supports other storage providers, including mounting of local directories into a container, but this is blocked by existing Gatekeeper policies. In general, the rules are: Data store : Any location, physical or logical, which is capable of storing user-generated data. Protected B data stores may be read and written to by a Protected B workload Protected B data stores may never be accessed from an unclassified workload Note: This proposal does not define sharing of data between Protected B workloads. This is left to the DAaaS project to elaborate and design should this funcationality be deemed necessary. Disk storage Access to disk storage will be restricted based on the classification of the disk and the classification of the pod it is being connected to. The following table describes the disk classification, disk mode and pod classification, and whether the combination is permitted or denied: Pod Classification Disk Classification Disk Mode Result Unclassified Unclassified Read only Permitted Unclassified Unclassified Read/write Permitted Unclassified Protected B Read only Denied Unclassified Protected B Read/write Denied Protected B Unclassified Read only Denied Protected B Unclassified Read/write Denied Protected B Protected B Read only Permitted Protected B Protected B Read/write Permitted Disk policies will be enforced by policy in Gatekeeper and the Open Policy Agent. Recommendation STR-DSK-01 : The above disk policy be applied to the AAW environment. Object storage A separate Protected B MinIO instance will be created for protected workloads. This MinIO instance will operate similar to the existing MinIO instances, except it will not be available outside of protected workloads (optionally, the web interface can be enabled and only available to Protected B workloads). Because this proposal does not contain any provisions on how to share data between Protected B workloads, there will be no shared folder instance on the Protected B MinIO object store. Restricted access to MinIO storage will be implemented using Network Policies . Recommendation STR-OBJ-01 : The above object storage policy be applied to the AAW environment. One-way synchronization with unclassified MinIO instance To facilitate fetching data from the internet, a one-way synchronization from the unclassified Standard MinIO instance will be performed. A write-only bucket on the Standard MinIO instance will be mirrored to a read-only bucket on the protected B MinIO instance. The synchronization pod will be the only pod which will be authorized to access both the Unclassified and Protected B MinIO instances. The credentials assigned to it will be: Read-only on the Unclassified instance in the \u201cSync\u201d bucket Write-only on the Protected B instance in the \u201cSync\u201d bucket All users will have write access to the \u201cSync\u201d bucket on the Unclassified instance, and all users will have read access to the \u201cSync\u201d bucket on the Protected B instance. Recommendation STR-OBJ-02 : The above object storage synchronization process be approved, providing a write-only bucket in the Unclassified instance mapped to a read-only bucket on the Protected B instance. Receiving and outputting Protected B data to/from AAW This proposal does not propose a solution for receiving Protected B data into the environment nor for extracting output from completed analysis. This will require coordination with the appropriate groups at Statistics Canada and will be left to the Data Analytics as a Service (DAaaS) project for elaboration and design.","title":"Storage"},{"location":"architecture/04-storage/#storage","text":"Data is the largest asset and attack surface of Protected B workloads within the Advanced Analytics Workspaces. This section is focusing on storage controlled by users directely. The AAW environment consists currently of two main types of user storage: Disk storage (attached to one pod at a time) Object storage Additionally, data is obtained from the following sources: Object storage (internal to AAW) Statistics Canada public data External data sources Kubernetes supports other storage providers, including mounting of local directories into a container, but this is blocked by existing Gatekeeper policies. In general, the rules are: Data store : Any location, physical or logical, which is capable of storing user-generated data. Protected B data stores may be read and written to by a Protected B workload Protected B data stores may never be accessed from an unclassified workload Note: This proposal does not define sharing of data between Protected B workloads. This is left to the DAaaS project to elaborate and design should this funcationality be deemed necessary.","title":"Storage"},{"location":"architecture/04-storage/#disk-storage","text":"Access to disk storage will be restricted based on the classification of the disk and the classification of the pod it is being connected to. The following table describes the disk classification, disk mode and pod classification, and whether the combination is permitted or denied: Pod Classification Disk Classification Disk Mode Result Unclassified Unclassified Read only Permitted Unclassified Unclassified Read/write Permitted Unclassified Protected B Read only Denied Unclassified Protected B Read/write Denied Protected B Unclassified Read only Denied Protected B Unclassified Read/write Denied Protected B Protected B Read only Permitted Protected B Protected B Read/write Permitted Disk policies will be enforced by policy in Gatekeeper and the Open Policy Agent. Recommendation STR-DSK-01 : The above disk policy be applied to the AAW environment.","title":"Disk storage"},{"location":"architecture/04-storage/#object-storage","text":"A separate Protected B MinIO instance will be created for protected workloads. This MinIO instance will operate similar to the existing MinIO instances, except it will not be available outside of protected workloads (optionally, the web interface can be enabled and only available to Protected B workloads). Because this proposal does not contain any provisions on how to share data between Protected B workloads, there will be no shared folder instance on the Protected B MinIO object store. Restricted access to MinIO storage will be implemented using Network Policies . Recommendation STR-OBJ-01 : The above object storage policy be applied to the AAW environment.","title":"Object storage"},{"location":"architecture/04-storage/#one-way-synchronization-with-unclassified-minio-instance","text":"To facilitate fetching data from the internet, a one-way synchronization from the unclassified Standard MinIO instance will be performed. A write-only bucket on the Standard MinIO instance will be mirrored to a read-only bucket on the protected B MinIO instance. The synchronization pod will be the only pod which will be authorized to access both the Unclassified and Protected B MinIO instances. The credentials assigned to it will be: Read-only on the Unclassified instance in the \u201cSync\u201d bucket Write-only on the Protected B instance in the \u201cSync\u201d bucket All users will have write access to the \u201cSync\u201d bucket on the Unclassified instance, and all users will have read access to the \u201cSync\u201d bucket on the Protected B instance. Recommendation STR-OBJ-02 : The above object storage synchronization process be approved, providing a write-only bucket in the Unclassified instance mapped to a read-only bucket on the Protected B instance.","title":"One-way synchronization with unclassified MinIO instance"},{"location":"architecture/04-storage/#receiving-and-outputting-protected-b-data-tofrom-aaw","text":"This proposal does not propose a solution for receiving Protected B data into the environment nor for extracting output from completed analysis. This will require coordination with the appropriate groups at Statistics Canada and will be left to the Data Analytics as a Service (DAaaS) project for elaboration and design.","title":"Receiving and outputting Protected B data to/from AAW"},{"location":"architecture/05-network/","text":"Network The next largest attack surface is the network. Controlling network access is fundamental to preventing the exfiltration of protected data. Within the protected workloads running in AAW, all network activity will be deny-by-default . Specific exemptions will be made for accessing authorized storage environments and systems, with each allowlisted service undergoing an assessment for its security posture with regards to data exfiltration. Relation with Azure controls : The AAW environment is relying on defense-in-depth, so there are multiple levels of network controls to restrict unauthorized network connectivity. Additionally, the Azure controls cannot restrict access to specific services within the cluster whereas the Kubernetes-level security controls can. Finally, it is also important that all network activity be encrypted using the Istio service mesh available in the Statistics Canada Cloud Native Platform. Network policies The primary mechanism for restricting network activity will be via Kubernetes Network Policies. Network policies are implemented in the Azure Kubernetes environment via the Linux iptables firewall on each node. Recommendation NET-POL-01 : That traffic to and from Protected B workloads in the cluster be deny-by-default. Exceptions be made for operational needs only. In-transit encryption Any service which is made available to Protected B workloads must be placed on the Istio Service Mesh, which provides automatic TLS encryption for all connectivity. Istio's TLS implementation is mutual TLS, therefore both the client and the server verify each other's identity. Recommendation NET-TR-01 : Istio be used for inter-service traffic of Protected B workloads, providing mutual TLS encryption. Recommendation NET-TR-02 : A gatekeeper policy be implemented which prevents disabling the Istio sidecar on Protected B workloads. Block the following annotations: sidecar.istio.io/inject: 'false' traffic.sidecar.istio.io/excludeOutboundPorts traffic.sidecar.istio.io/excludeOutboundIPRanges traffic.sidecar.istio.io/excludeInboundPorts traffic.sidecar.istio.io/excludeInboundIPRanges Block containers from running as user 1337 , which bypasses the Istio proxy External services Protected B workloads should not connect directly to any external service. Recommendation NET-ES-01 : Requests should be mediated through a service running in the AAW Kubernetes cluster, where possible. If not possible, then the service is to allow-listed on the firewall, since the firewall is deny-by-default. For protected workloads, these exceptions should be limited. Packages Artifactory provides a package-proxy, which will provide the necessary mediation between Protected B workloads and the remote repositories. Artifactory is already utilized within the Statistics Canada main cloud environment, so there is operational knowledge of the system. Package sources should be limited due to the potential risk they can introduce. NOTE : This will require a paid Artifactory license. Alternatively, installation of packages is not permitted. Only packages available in the compiled Docker images would be made available in the environment. Recommendation NET-ES-02 : Packages be provided through an Artifactory instance running in the AAW environment. Recommendation NET-ES-03 : X-Ray should be installed alongside Artifactory to provide for CVE scanning of packages being imported into the environment. The use of Artifactory would also open up the possibility of user repositories should this become a desired function of the Advanced Analytics Workspaces. Source code Access to a source code system was identified during discussions of the AAW environment. A source code system available to both unclassified and Protected B workloads introduces some complications from a security posture, and in particular how to prevent data exfiltration from the environment. Therefore, there are three proposals on how to implement a source code system in AAW: Recommendation NET-ES-03 : For source code, Continue to use external source code systems for unclassified workloads. This is permitted via TBS policy: 6.1: Departments are to enable open access to the Internet for GC electronic networks and devices, including GC and external Web 2.0 tools and services, to authorized individuals, as per Section 6.1.3 of the Policy on Acceptable Network and Device Use (PANDU). \u2014 https://www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=32588#cha5 and launch an internal-only GitLab instance accessible only to Protected B workloads. Launch a GitLab instance in the AAW environment which is available to all workloads. Workloads running at the Protected B level are granted only HEAD / GET requests to the GitLab instance (to prevent data exfiltration). POST requests to specificly authorized endpoints, such as for authorization, will be allowed. Two seperate GitLab instances be launched in the AAW environment, 1 for unclassified and 1 for Protected B. This is the least recommended solution due to the maintenance overhead. DAaaS should identify the best solution based on the needs of its users, and therefore this proposal does not specify a specific solution.","title":"Network"},{"location":"architecture/05-network/#network","text":"The next largest attack surface is the network. Controlling network access is fundamental to preventing the exfiltration of protected data. Within the protected workloads running in AAW, all network activity will be deny-by-default . Specific exemptions will be made for accessing authorized storage environments and systems, with each allowlisted service undergoing an assessment for its security posture with regards to data exfiltration. Relation with Azure controls : The AAW environment is relying on defense-in-depth, so there are multiple levels of network controls to restrict unauthorized network connectivity. Additionally, the Azure controls cannot restrict access to specific services within the cluster whereas the Kubernetes-level security controls can. Finally, it is also important that all network activity be encrypted using the Istio service mesh available in the Statistics Canada Cloud Native Platform.","title":"Network"},{"location":"architecture/05-network/#network-policies","text":"The primary mechanism for restricting network activity will be via Kubernetes Network Policies. Network policies are implemented in the Azure Kubernetes environment via the Linux iptables firewall on each node. Recommendation NET-POL-01 : That traffic to and from Protected B workloads in the cluster be deny-by-default. Exceptions be made for operational needs only.","title":"Network policies"},{"location":"architecture/05-network/#in-transit-encryption","text":"Any service which is made available to Protected B workloads must be placed on the Istio Service Mesh, which provides automatic TLS encryption for all connectivity. Istio's TLS implementation is mutual TLS, therefore both the client and the server verify each other's identity. Recommendation NET-TR-01 : Istio be used for inter-service traffic of Protected B workloads, providing mutual TLS encryption. Recommendation NET-TR-02 : A gatekeeper policy be implemented which prevents disabling the Istio sidecar on Protected B workloads. Block the following annotations: sidecar.istio.io/inject: 'false' traffic.sidecar.istio.io/excludeOutboundPorts traffic.sidecar.istio.io/excludeOutboundIPRanges traffic.sidecar.istio.io/excludeInboundPorts traffic.sidecar.istio.io/excludeInboundIPRanges Block containers from running as user 1337 , which bypasses the Istio proxy","title":"In-transit encryption"},{"location":"architecture/05-network/#external-services","text":"Protected B workloads should not connect directly to any external service. Recommendation NET-ES-01 : Requests should be mediated through a service running in the AAW Kubernetes cluster, where possible. If not possible, then the service is to allow-listed on the firewall, since the firewall is deny-by-default. For protected workloads, these exceptions should be limited.","title":"External services"},{"location":"architecture/05-network/#packages","text":"Artifactory provides a package-proxy, which will provide the necessary mediation between Protected B workloads and the remote repositories. Artifactory is already utilized within the Statistics Canada main cloud environment, so there is operational knowledge of the system. Package sources should be limited due to the potential risk they can introduce. NOTE : This will require a paid Artifactory license. Alternatively, installation of packages is not permitted. Only packages available in the compiled Docker images would be made available in the environment. Recommendation NET-ES-02 : Packages be provided through an Artifactory instance running in the AAW environment. Recommendation NET-ES-03 : X-Ray should be installed alongside Artifactory to provide for CVE scanning of packages being imported into the environment. The use of Artifactory would also open up the possibility of user repositories should this become a desired function of the Advanced Analytics Workspaces.","title":"Packages"},{"location":"architecture/05-network/#source-code","text":"Access to a source code system was identified during discussions of the AAW environment. A source code system available to both unclassified and Protected B workloads introduces some complications from a security posture, and in particular how to prevent data exfiltration from the environment. Therefore, there are three proposals on how to implement a source code system in AAW: Recommendation NET-ES-03 : For source code, Continue to use external source code systems for unclassified workloads. This is permitted via TBS policy: 6.1: Departments are to enable open access to the Internet for GC electronic networks and devices, including GC and external Web 2.0 tools and services, to authorized individuals, as per Section 6.1.3 of the Policy on Acceptable Network and Device Use (PANDU). \u2014 https://www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=32588#cha5 and launch an internal-only GitLab instance accessible only to Protected B workloads. Launch a GitLab instance in the AAW environment which is available to all workloads. Workloads running at the Protected B level are granted only HEAD / GET requests to the GitLab instance (to prevent data exfiltration). POST requests to specificly authorized endpoints, such as for authorization, will be allowed. Two seperate GitLab instances be launched in the AAW environment, 1 for unclassified and 1 for Protected B. This is the least recommended solution due to the maintenance overhead. DAaaS should identify the best solution based on the needs of its users, and therefore this proposal does not specify a specific solution.","title":"Source code"},{"location":"architecture/06-kubernetes/","text":"Kubernetes Note: Generally in this section, the terminology of namespace vs. profile is interchangeable. Profiles map directly to a namespace, and in the AAW environment user namespaces are not seperately provisioned. Workloads scheduling Kubernetes has a diverse and powerful scheduler for locating user-level resources. Appropriate configuration of resources will ensure that workloads get scheduled on the appropriate nodes. Node labels + taints Each node pool in Kubernetes will have a set of labels applied that will assist with the scheduling of workloads on the appropriate nodes. Label Value Purpose data.statcan.gc.ca/classification (unclassified|protected-b) Maximum data classification of the node node.statcan.gc.ca/purpose (system|user) Purpose of the node Namespaces labels System namespaces will be identified by Label Value Purpose namespace.statcan.gc.ca/purpose (system|daaas|user) Purpose of the namespace. Node selectors on workloads Recommendation KUBE-NODE-01 : All pods must have a nodeSelector which indicates the criteria for a node selection, requiring both the classification and purpose labels for any workload being scheduled in the AAW environment. This will be enforced by Gatekeeper. Note: this restriction will not apply to workloads created by the Azure Kubernetes Service as we do not have control over them. Note: Setting node.statcan.gc.ca/purpose=system as a node selector is only permitted from namespaces having namespace.statcan.gc.ca/purpose=system and namespace.statcan.gc.ca/purpose=daaas . If namespace.statcan.gc.ca/purpose is unset on a namespace, then the namespace is assumed to be a user namesapce. Images The current Advanced Analytics Workspaces (AAW) environment restricts where the container images are authorized to be pulled from (https://github.com/StatCan/gatekeeper-policies/blob/master/general/container-allowed-images/constraint.yaml). The current list of images is very large and shouldn't be used for Protected B workloads. Recommendation KUBE-IMG-01 : All container images associated with platform components must be stored in an AAW controlled image repository. Recommendation KUBE-IMG-02 : The authorized image list for Protected B workloads be restricted to AAW controlled image repositories only. Recommendation KUBE-IMG-03 : The authorized image list for unclassified workloads be further restricted than what is currently in place. Ideally, this list should be restricted to AAW controller image repositories only. Recommendation KUBE-IMG-04 : Images running in the environment must align with CIS benchmarks. Images in the production environment must be built via an automated build pipeline which includes a dockle scan (for CIS benchmarks). In particular, user containers must not run as the ROOT user. Images built by developers must be restricted to the development environment. This can be accomplished via a different repository, where the production environment does not have permissions to the dev repository. Recommendation KUBE-IMG-05 : User namespaces contain image pull credentials which restrict read-only access in Artifactory to: DAaaS kubeflow images repository Repositories assigned to the namespace Gatekeeper / Open Policy Agent Gatekeeper and the Open Policy Agent provide a mechanism for enforcing business policies on Kubernetes resources. Gatekeeper is a Kubernetes webhook, which provides a callback that is executed when a resource is created, updated or deleted. Gatekeeper is intented to enforce many of the policies suggested in this proposal. Recommendation KUBE-GK-01 : Gatekeeper be configured in a default-closed configuration, ensuring that if Gatekeeper is unavailable that all changes are blocked. This ensures that policy violations are not introduced in the event of a Gatekeeper outage. Recommendation KUBE-GK-02 : Gatekeeper configuration be reviewed to ensure that it is highly-available and will scale with any increased load, to prevent a system outage. Recommendation KUBE-GK-03 : Existing policies in https://github.com/StatCan/gatekeeper-policies be used. Any policy currently in \"audit\" state should be moved to enforce state on user namesapces. Recommendation KUBE-GK-04 : A gatekeeper policy be created which prevents kubectl exec on any pods marked with a classification of protected-b . Recommendation KUBE-GK-05 : A gatekeeper policy be created which prevents kubectl cp on any pods marked with a classification of protected-b . Access control Kubernetes has a robust Role-Based Access Control (RBAC) system, that enables fine-grained control over a user's permissions within the cluster. Recommendation KUBE-RBAC-01 : That the following Azure AD groups be created to align with Kubernetes roles: DAaaS-Breakglass-Admins : Full administrative access to the entire system, including user namespaces. Users in this group may access the admin configuration context in the event that Azure AD authentication is not functioning. This group should be assigned to admin cloud accounts only, and not to normal user account. 2. DAaaS-Platform-Admins : Full administrative access to system, no access to DAaaS or user namespaces. 3. DAaaS-Admins : Access to DAaaS system namespaces, no access to user namespaces. 4. DAaaS-Support : Limited access to user namespaces to provide general debugging support. 5. DAaaS-Users : No global RBAC configuration. Users will typically be granted access to any profiles they have access to. All \"-admins\" and \"-support\" roles are to have the permission to pull the Kubernetes configuration file to access the cluster. Recommendation KUBE-RBAC-01a : As an extension of KUBE-RBAC-01, this recommendation further elaborates the permissions assigned to the DAaaS-Support group. Read and list all resources associated with the Kubeflow environment: Profiles , Deployments , Statefulsets , Replicasets , Pods , Notebooks , Workflows , PersistentVolumeClaims , Roles , RoleBindings , Events , ResourceLimits . List ConfigMaps and Secrets (no read due to the possibility of of sensitive values) Read and list Nodes Recommendation KUBE-RBAC-02 : Kubeflow assigns a large set of permissions to the default-editor account. These permissions should be reviewed and restricted to essential/functional needs only. This is an ongoing excercise outside of this proposal, therefore I will not propose specific requirements, but instead strongly recommend that the excercise be continued and completed . Recommendation KUBE-RBAC-03 : To better restrict user access to the AAW environment, access to any web application which allows interaction with any compute or storage, other than publicly accessible component, is to be limited to the DAaaS-Users group. Resource quotas Users, whether intentional or accidental, can perform a \"Denial of Service\" attack against the environment, making the environment unavailable to others. Recommendation KUBE-RSRC-01 : Resource quotas be implemented on all namespaces to prevent an intential or accidental denial of service attack against the cluster. Info: https://kubernetes.io/docs/concepts/policy/resource-quotas/ A further excercise will be required to identify reasonable limits to put in place for each namespace .","title":"Kubernetes"},{"location":"architecture/06-kubernetes/#kubernetes","text":"Note: Generally in this section, the terminology of namespace vs. profile is interchangeable. Profiles map directly to a namespace, and in the AAW environment user namespaces are not seperately provisioned.","title":"Kubernetes"},{"location":"architecture/06-kubernetes/#workloads-scheduling","text":"Kubernetes has a diverse and powerful scheduler for locating user-level resources. Appropriate configuration of resources will ensure that workloads get scheduled on the appropriate nodes.","title":"Workloads scheduling"},{"location":"architecture/06-kubernetes/#node-labels-taints","text":"Each node pool in Kubernetes will have a set of labels applied that will assist with the scheduling of workloads on the appropriate nodes. Label Value Purpose data.statcan.gc.ca/classification (unclassified|protected-b) Maximum data classification of the node node.statcan.gc.ca/purpose (system|user) Purpose of the node","title":"Node labels + taints"},{"location":"architecture/06-kubernetes/#namespaces-labels","text":"System namespaces will be identified by Label Value Purpose namespace.statcan.gc.ca/purpose (system|daaas|user) Purpose of the namespace.","title":"Namespaces labels"},{"location":"architecture/06-kubernetes/#node-selectors-on-workloads","text":"Recommendation KUBE-NODE-01 : All pods must have a nodeSelector which indicates the criteria for a node selection, requiring both the classification and purpose labels for any workload being scheduled in the AAW environment. This will be enforced by Gatekeeper. Note: this restriction will not apply to workloads created by the Azure Kubernetes Service as we do not have control over them. Note: Setting node.statcan.gc.ca/purpose=system as a node selector is only permitted from namespaces having namespace.statcan.gc.ca/purpose=system and namespace.statcan.gc.ca/purpose=daaas . If namespace.statcan.gc.ca/purpose is unset on a namespace, then the namespace is assumed to be a user namesapce.","title":"Node selectors on workloads"},{"location":"architecture/06-kubernetes/#images","text":"The current Advanced Analytics Workspaces (AAW) environment restricts where the container images are authorized to be pulled from (https://github.com/StatCan/gatekeeper-policies/blob/master/general/container-allowed-images/constraint.yaml). The current list of images is very large and shouldn't be used for Protected B workloads. Recommendation KUBE-IMG-01 : All container images associated with platform components must be stored in an AAW controlled image repository. Recommendation KUBE-IMG-02 : The authorized image list for Protected B workloads be restricted to AAW controlled image repositories only. Recommendation KUBE-IMG-03 : The authorized image list for unclassified workloads be further restricted than what is currently in place. Ideally, this list should be restricted to AAW controller image repositories only. Recommendation KUBE-IMG-04 : Images running in the environment must align with CIS benchmarks. Images in the production environment must be built via an automated build pipeline which includes a dockle scan (for CIS benchmarks). In particular, user containers must not run as the ROOT user. Images built by developers must be restricted to the development environment. This can be accomplished via a different repository, where the production environment does not have permissions to the dev repository. Recommendation KUBE-IMG-05 : User namespaces contain image pull credentials which restrict read-only access in Artifactory to: DAaaS kubeflow images repository Repositories assigned to the namespace","title":"Images"},{"location":"architecture/06-kubernetes/#gatekeeper-open-policy-agent","text":"Gatekeeper and the Open Policy Agent provide a mechanism for enforcing business policies on Kubernetes resources. Gatekeeper is a Kubernetes webhook, which provides a callback that is executed when a resource is created, updated or deleted. Gatekeeper is intented to enforce many of the policies suggested in this proposal. Recommendation KUBE-GK-01 : Gatekeeper be configured in a default-closed configuration, ensuring that if Gatekeeper is unavailable that all changes are blocked. This ensures that policy violations are not introduced in the event of a Gatekeeper outage. Recommendation KUBE-GK-02 : Gatekeeper configuration be reviewed to ensure that it is highly-available and will scale with any increased load, to prevent a system outage. Recommendation KUBE-GK-03 : Existing policies in https://github.com/StatCan/gatekeeper-policies be used. Any policy currently in \"audit\" state should be moved to enforce state on user namesapces. Recommendation KUBE-GK-04 : A gatekeeper policy be created which prevents kubectl exec on any pods marked with a classification of protected-b . Recommendation KUBE-GK-05 : A gatekeeper policy be created which prevents kubectl cp on any pods marked with a classification of protected-b .","title":"Gatekeeper / Open Policy Agent"},{"location":"architecture/06-kubernetes/#access-control","text":"Kubernetes has a robust Role-Based Access Control (RBAC) system, that enables fine-grained control over a user's permissions within the cluster. Recommendation KUBE-RBAC-01 : That the following Azure AD groups be created to align with Kubernetes roles: DAaaS-Breakglass-Admins : Full administrative access to the entire system, including user namespaces. Users in this group may access the admin configuration context in the event that Azure AD authentication is not functioning. This group should be assigned to admin cloud accounts only, and not to normal user account. 2. DAaaS-Platform-Admins : Full administrative access to system, no access to DAaaS or user namespaces. 3. DAaaS-Admins : Access to DAaaS system namespaces, no access to user namespaces. 4. DAaaS-Support : Limited access to user namespaces to provide general debugging support. 5. DAaaS-Users : No global RBAC configuration. Users will typically be granted access to any profiles they have access to. All \"-admins\" and \"-support\" roles are to have the permission to pull the Kubernetes configuration file to access the cluster. Recommendation KUBE-RBAC-01a : As an extension of KUBE-RBAC-01, this recommendation further elaborates the permissions assigned to the DAaaS-Support group. Read and list all resources associated with the Kubeflow environment: Profiles , Deployments , Statefulsets , Replicasets , Pods , Notebooks , Workflows , PersistentVolumeClaims , Roles , RoleBindings , Events , ResourceLimits . List ConfigMaps and Secrets (no read due to the possibility of of sensitive values) Read and list Nodes Recommendation KUBE-RBAC-02 : Kubeflow assigns a large set of permissions to the default-editor account. These permissions should be reviewed and restricted to essential/functional needs only. This is an ongoing excercise outside of this proposal, therefore I will not propose specific requirements, but instead strongly recommend that the excercise be continued and completed . Recommendation KUBE-RBAC-03 : To better restrict user access to the AAW environment, access to any web application which allows interaction with any compute or storage, other than publicly accessible component, is to be limited to the DAaaS-Users group.","title":"Access control"},{"location":"architecture/06-kubernetes/#resource-quotas","text":"Users, whether intentional or accidental, can perform a \"Denial of Service\" attack against the environment, making the environment unavailable to others. Recommendation KUBE-RSRC-01 : Resource quotas be implemented on all namespaces to prevent an intential or accidental denial of service attack against the cluster. Info: https://kubernetes.io/docs/concepts/policy/resource-quotas/ A further excercise will be required to identify reasonable limits to put in place for each namespace .","title":"Resource quotas"},{"location":"architecture/07-kubeflow/","text":"Kubeflow Kubeflow Notebooks Kubeflow Notebooks are the main component of the AAW environment that is relied upon by users to perform their analysis processes. These notebooks, while powerful, contain functionality that are directly in violation of Protected B controls. Therefore, for Kubeflow Notebooks to be used with Protected B data: Recommendation KF-NB-01 : The download functionality be disabled in the Kubeflow Notebooks environment, if possible. Assuming this functionality is provided by means of a URL, then the URL can be restricted using Istio. Recommendation KF-NB-02 : The copy/paste functionality be disabled in the Kubeflow Notebooks environment, if possible. To make a notebook Protected B capable, a \"Configuration\" option will be added that applies the appropriate configuration for Protected B workloads. This includes: Adding data.statcan.gc.ca/classification labels to PVCs and Pods This may require some modification to the Jupyter Web app or Notebook controller. Pipelines Pipelines is a powerful component of Kubeflow for \"building and deploying portable, scalable, machine learning (ML) workflows based on Docker Containers\". Unfortunately, due to the current design of pipelines, there is no possibility to seperate Unclassified and Protected B pipelines, even with the appropriate labelling in place on resources because the final output and artifacts are stored in an uncontrolled MinIO object store. Recommendation KF-PL-01 : Kubeflow Pipelines be disabled for Protected B workloads, enforced by Gatekeeper, until the pipelines system can be appropriately isolated between users and data classifications. Contributors Kubeflow provides the ability to shared profiles with other users of the Advanced Analytics Workspaces (AAW). Given the high likelihood of users needing to collaborate on Protected B workloads, this should not be restricted in the environment. Recommendation KUBE-CONTRIB-01 : Profile contributors continue to be permitted in the environment. A reminder / terms of usage should be sent to users onboarding into the environment that they are responsible for maintaining the \"Need to Know\" of Protected B data when adding contributors to a profile they own.","title":"Kubeflow"},{"location":"architecture/07-kubeflow/#kubeflow","text":"","title":"Kubeflow"},{"location":"architecture/07-kubeflow/#kubeflow-notebooks","text":"Kubeflow Notebooks are the main component of the AAW environment that is relied upon by users to perform their analysis processes. These notebooks, while powerful, contain functionality that are directly in violation of Protected B controls. Therefore, for Kubeflow Notebooks to be used with Protected B data: Recommendation KF-NB-01 : The download functionality be disabled in the Kubeflow Notebooks environment, if possible. Assuming this functionality is provided by means of a URL, then the URL can be restricted using Istio. Recommendation KF-NB-02 : The copy/paste functionality be disabled in the Kubeflow Notebooks environment, if possible. To make a notebook Protected B capable, a \"Configuration\" option will be added that applies the appropriate configuration for Protected B workloads. This includes: Adding data.statcan.gc.ca/classification labels to PVCs and Pods This may require some modification to the Jupyter Web app or Notebook controller.","title":"Kubeflow Notebooks"},{"location":"architecture/07-kubeflow/#pipelines","text":"Pipelines is a powerful component of Kubeflow for \"building and deploying portable, scalable, machine learning (ML) workflows based on Docker Containers\". Unfortunately, due to the current design of pipelines, there is no possibility to seperate Unclassified and Protected B pipelines, even with the appropriate labelling in place on resources because the final output and artifacts are stored in an uncontrolled MinIO object store. Recommendation KF-PL-01 : Kubeflow Pipelines be disabled for Protected B workloads, enforced by Gatekeeper, until the pipelines system can be appropriately isolated between users and data classifications.","title":"Pipelines"},{"location":"architecture/07-kubeflow/#contributors","text":"Kubeflow provides the ability to shared profiles with other users of the Advanced Analytics Workspaces (AAW). Given the high likelihood of users needing to collaborate on Protected B workloads, this should not be restricted in the environment. Recommendation KUBE-CONTRIB-01 : Profile contributors continue to be permitted in the environment. A reminder / terms of usage should be sent to users onboarding into the environment that they are responsible for maintaining the \"Need to Know\" of Protected B data when adding contributors to a profile they own.","title":"Contributors"},{"location":"architecture/08-appendix-a/","text":"Appendix A: Non-security recommendations During the investigation into securing the AAW environment, additional non-security related recommendations have been identified. These are not included as official recommendations as they are out of scope, but they are included below for informational purposes: Profile automation Today, the AAW environment performs a series of configuration upon the creation of new user profiles. In continuing with these efforts, and with the addition of tooling provided by this proposal, that the AAW team: Recommendation APNDXA-PROF-01 : Split the custom StatCan profile-configurator into multiple, small controllers. Each controller would be responsible for one configuration item. Recommendation APNDXA-PROF-02 : The custom controllers additionally apply configuration that: Create a local docker repository in Artifactory Generate image pull credentials for Artifactory, applicable only to the namespace Configure the GitLab instance by pre-creating a GitLab group. (additional): If desired to manage the GitLab group membership, the controller will update on a regular basis as contributors are added and removed from the namespace. Azure Kubernetes Service (AKS) APNDXA-AKS-01 : Longer term, as more heavy analytical-based workloads are run in the AAW environment, it is recommended that the DAaaS team investigate the use of spot node pools . If determined to be a viable option, then the following node pools would be added to the AAW AKS cluster: Pool VM Type Subnet Purpose spot-unclassified Standard_D16s_v3 user-unclassified Unclassified user spot workloads spot-protected-b Standard_D16s_v3 user-protected-b Protected B user spot workloads","title":"Appendix A: Non-security recommendations"},{"location":"architecture/08-appendix-a/#appendix-a-non-security-recommendations","text":"During the investigation into securing the AAW environment, additional non-security related recommendations have been identified. These are not included as official recommendations as they are out of scope, but they are included below for informational purposes:","title":"Appendix A: Non-security recommendations"},{"location":"architecture/08-appendix-a/#profile-automation","text":"Today, the AAW environment performs a series of configuration upon the creation of new user profiles. In continuing with these efforts, and with the addition of tooling provided by this proposal, that the AAW team: Recommendation APNDXA-PROF-01 : Split the custom StatCan profile-configurator into multiple, small controllers. Each controller would be responsible for one configuration item. Recommendation APNDXA-PROF-02 : The custom controllers additionally apply configuration that: Create a local docker repository in Artifactory Generate image pull credentials for Artifactory, applicable only to the namespace Configure the GitLab instance by pre-creating a GitLab group. (additional): If desired to manage the GitLab group membership, the controller will update on a regular basis as contributors are added and removed from the namespace.","title":"Profile automation"},{"location":"architecture/08-appendix-a/#azure-kubernetes-service-aks","text":"APNDXA-AKS-01 : Longer term, as more heavy analytical-based workloads are run in the AAW environment, it is recommended that the DAaaS team investigate the use of spot node pools . If determined to be a viable option, then the following node pools would be added to the AAW AKS cluster: Pool VM Type Subnet Purpose spot-unclassified Standard_D16s_v3 user-unclassified Unclassified user spot workloads spot-protected-b Standard_D16s_v3 user-protected-b Protected B user spot workloads","title":"Azure Kubernetes Service (AKS)"},{"location":"daaas-system/namespace-controller/","text":"namespace-controller This repository implements a simple controller for watching Foo resources as defined with a CustomResourceDefinition (CRD). Note: go-get or vendor this package as k8s.io/namespace-controller . This particular example demonstrates how to perform basic operations such as: How to register a new custom resource (custom resource type) of type Foo using a CustomResourceDefinition. How to create/get/list instances of your new resource type Foo . How to setup a controller on resource handling create/update/delete events. It makes use of the generators in k8s.io/code-generator to generate a typed client, informers, listers and deep-copy functions. You can do this yourself using the ./hack/update-codegen.sh script. The update-codegen script will automatically generate the following files & directories: pkg/apis/namespacecontroller/v1alpha1/zz_generated.deepcopy.go pkg/generated/ Changes should not be made to these files manually, and when creating your own controller based off of this implementation you should not copy these files and instead run the update-codegen script to generate your own. Details The namespace controller uses client-go library extensively. The details of interaction points of the namespace controller with various mechanisms from this library are explained here . Fetch namespace-controller and its dependencies Like the rest of Kubernetes, namespace-controller has used godep and $GOPATH for years and is now adopting go 1.11 modules. There are thus two alternative ways to go about fetching this demo and its dependencies. Fetch with godep When NOT using go 1.11 modules, you can use the following commands. go get -d k8s.io/namespace-controller cd $GOPATH/src/k8s.io/namespace-controller godep restore When using go 1.11 modules When using go 1.11 modules ( GO111MODULE=on ), issue the following commands --- starting in whatever working directory you like. git clone https://github.com/kubernetes/namespace-controller.git cd namespace-controller Note, however, that if you intend to generate code then you will also need the code-generator repo to exist in an old-style location. One easy way to do this is to use the command go mod vendor to create and populate the vendor directory. A Note on kubernetes/kubernetes If you are developing Kubernetes according to https://github.com/kubernetes/community/blob/master/contributors/guide/github-workflow.md then you already have a copy of this demo in kubernetes/staging/src/k8s.io/namespace-controller and its dependencies --- including the code generator --- are in usable locations (valid for all Go versions). Purpose This is an example of how to build a kube-like controller with a single type. Running Prerequisite : Since the namespace-controller uses apps/v1 deployments, the Kubernetes cluster version should be greater than 1.9. # assumes you have a working kubeconfig, not required if operating in-cluster go build -o namespace-controller . ./namespace-controller -kubeconfig=$HOME/.kube/config # create a CustomResourceDefinition kubectl create -f artifacts/examples/crd.yaml # create a custom resource of type Foo kubectl create -f artifacts/examples/example-foo.yaml # check deployments created through the custom resource kubectl get deployments Use Cases CustomResourceDefinitions can be used to implement custom resource types for your Kubernetes cluster. These act like most other Resources in Kubernetes, and may be kubectl apply 'd, etc. Some example use cases: Provisioning/Management of external datastores/databases (eg. CloudSQL/RDS instances) Higher level abstractions around Kubernetes primitives (eg. a single Resource to define an etcd cluster, backed by a Service and a ReplicationController) Defining types Each instance of your custom resource has an attached Spec, which should be defined via a struct{} to provide data format validation. In practice, this Spec is arbitrary key-value data that specifies the configuration/behavior of your Resource. For example, if you were implementing a custom resource for a Database, you might provide a DatabaseSpec like the following: type DatabaseSpec struct { Databases []string `json:\"databases\"` Users []User `json:\"users\"` Version string `json:\"version\"` } type User struct { Name string `json:\"name\"` Password string `json:\"password\"` } Validation To validate custom resources, use the CustomResourceValidation feature. Validation in the form of a structured schema is mandatory to be provided for apiextensions.k8s.io/v1 . Example The schema in crd.yaml applies the following validation on the custom resource: spec.replicas must be an integer and must have a minimum value of 1 and a maximum value of 10. Subresources Custom Resources support /status and /scale subresources . The CustomResourceSubresources feature is in GA from v1.16. Example The CRD in crd-status-subresource.yaml enables the /status subresource for custom resources. This means that UpdateStatus can be used by the controller to update only the status part of the custom resource. To understand why only the status part of the custom resource should be updated, please refer to the Kubernetes API conventions . In the above steps, use crd-status-subresource.yaml to create the CRD: # create a CustomResourceDefinition supporting the status subresource kubectl create -f artifacts/examples/crd-status-subresource.yaml A Note on the API version The group version of the custom resource in crd.yaml is v1alpha , this can be evolved to a stable API version, v1 , using CRD Versioning . Cleanup You can clean up the created CustomResourceDefinition with: kubectl delete crd foos.namespacecontroller.k8s.io Compatibility HEAD of this repository will match HEAD of k8s.io/apimachinery and k8s.io/client-go. Where does it come from? namespace-controller is synced from https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/namespace-controller. Code changes are made in that location, merged into k8s.io/kubernetes and later synced here.","title":"namespace-controller"},{"location":"daaas-system/namespace-controller/#namespace-controller","text":"This repository implements a simple controller for watching Foo resources as defined with a CustomResourceDefinition (CRD). Note: go-get or vendor this package as k8s.io/namespace-controller . This particular example demonstrates how to perform basic operations such as: How to register a new custom resource (custom resource type) of type Foo using a CustomResourceDefinition. How to create/get/list instances of your new resource type Foo . How to setup a controller on resource handling create/update/delete events. It makes use of the generators in k8s.io/code-generator to generate a typed client, informers, listers and deep-copy functions. You can do this yourself using the ./hack/update-codegen.sh script. The update-codegen script will automatically generate the following files & directories: pkg/apis/namespacecontroller/v1alpha1/zz_generated.deepcopy.go pkg/generated/ Changes should not be made to these files manually, and when creating your own controller based off of this implementation you should not copy these files and instead run the update-codegen script to generate your own.","title":"namespace-controller"},{"location":"daaas-system/namespace-controller/#details","text":"The namespace controller uses client-go library extensively. The details of interaction points of the namespace controller with various mechanisms from this library are explained here .","title":"Details"},{"location":"daaas-system/namespace-controller/#fetch-namespace-controller-and-its-dependencies","text":"Like the rest of Kubernetes, namespace-controller has used godep and $GOPATH for years and is now adopting go 1.11 modules. There are thus two alternative ways to go about fetching this demo and its dependencies.","title":"Fetch namespace-controller and its dependencies"},{"location":"daaas-system/namespace-controller/#fetch-with-godep","text":"When NOT using go 1.11 modules, you can use the following commands. go get -d k8s.io/namespace-controller cd $GOPATH/src/k8s.io/namespace-controller godep restore","title":"Fetch with godep"},{"location":"daaas-system/namespace-controller/#when-using-go-111-modules","text":"When using go 1.11 modules ( GO111MODULE=on ), issue the following commands --- starting in whatever working directory you like. git clone https://github.com/kubernetes/namespace-controller.git cd namespace-controller Note, however, that if you intend to generate code then you will also need the code-generator repo to exist in an old-style location. One easy way to do this is to use the command go mod vendor to create and populate the vendor directory.","title":"When using go 1.11 modules"},{"location":"daaas-system/namespace-controller/#a-note-on-kuberneteskubernetes","text":"If you are developing Kubernetes according to https://github.com/kubernetes/community/blob/master/contributors/guide/github-workflow.md then you already have a copy of this demo in kubernetes/staging/src/k8s.io/namespace-controller and its dependencies --- including the code generator --- are in usable locations (valid for all Go versions).","title":"A Note on kubernetes/kubernetes"},{"location":"daaas-system/namespace-controller/#purpose","text":"This is an example of how to build a kube-like controller with a single type.","title":"Purpose"},{"location":"daaas-system/namespace-controller/#running","text":"Prerequisite : Since the namespace-controller uses apps/v1 deployments, the Kubernetes cluster version should be greater than 1.9. # assumes you have a working kubeconfig, not required if operating in-cluster go build -o namespace-controller . ./namespace-controller -kubeconfig=$HOME/.kube/config # create a CustomResourceDefinition kubectl create -f artifacts/examples/crd.yaml # create a custom resource of type Foo kubectl create -f artifacts/examples/example-foo.yaml # check deployments created through the custom resource kubectl get deployments","title":"Running"},{"location":"daaas-system/namespace-controller/#use-cases","text":"CustomResourceDefinitions can be used to implement custom resource types for your Kubernetes cluster. These act like most other Resources in Kubernetes, and may be kubectl apply 'd, etc. Some example use cases: Provisioning/Management of external datastores/databases (eg. CloudSQL/RDS instances) Higher level abstractions around Kubernetes primitives (eg. a single Resource to define an etcd cluster, backed by a Service and a ReplicationController)","title":"Use Cases"},{"location":"daaas-system/namespace-controller/#defining-types","text":"Each instance of your custom resource has an attached Spec, which should be defined via a struct{} to provide data format validation. In practice, this Spec is arbitrary key-value data that specifies the configuration/behavior of your Resource. For example, if you were implementing a custom resource for a Database, you might provide a DatabaseSpec like the following: type DatabaseSpec struct { Databases []string `json:\"databases\"` Users []User `json:\"users\"` Version string `json:\"version\"` } type User struct { Name string `json:\"name\"` Password string `json:\"password\"` }","title":"Defining types"},{"location":"daaas-system/namespace-controller/#validation","text":"To validate custom resources, use the CustomResourceValidation feature. Validation in the form of a structured schema is mandatory to be provided for apiextensions.k8s.io/v1 .","title":"Validation"},{"location":"daaas-system/namespace-controller/#example","text":"The schema in crd.yaml applies the following validation on the custom resource: spec.replicas must be an integer and must have a minimum value of 1 and a maximum value of 10.","title":"Example"},{"location":"daaas-system/namespace-controller/#subresources","text":"Custom Resources support /status and /scale subresources . The CustomResourceSubresources feature is in GA from v1.16.","title":"Subresources"},{"location":"daaas-system/namespace-controller/#example_1","text":"The CRD in crd-status-subresource.yaml enables the /status subresource for custom resources. This means that UpdateStatus can be used by the controller to update only the status part of the custom resource. To understand why only the status part of the custom resource should be updated, please refer to the Kubernetes API conventions . In the above steps, use crd-status-subresource.yaml to create the CRD: # create a CustomResourceDefinition supporting the status subresource kubectl create -f artifacts/examples/crd-status-subresource.yaml","title":"Example"},{"location":"daaas-system/namespace-controller/#a-note-on-the-api-version","text":"The group version of the custom resource in crd.yaml is v1alpha , this can be evolved to a stable API version, v1 , using CRD Versioning .","title":"A Note on the API version"},{"location":"daaas-system/namespace-controller/#cleanup","text":"You can clean up the created CustomResourceDefinition with: kubectl delete crd foos.namespacecontroller.k8s.io","title":"Cleanup"},{"location":"daaas-system/namespace-controller/#compatibility","text":"HEAD of this repository will match HEAD of k8s.io/apimachinery and k8s.io/client-go.","title":"Compatibility"},{"location":"daaas-system/namespace-controller/#where-does-it-come-from","text":"namespace-controller is synced from https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/namespace-controller. Code changes are made in that location, merged into k8s.io/kubernetes and later synced here.","title":"Where does it come from?"},{"location":"daaas-system/network-policies/","text":"This repo, which is private, points specifically to system resources, such as Artifactory, the MinIO systems, and kubernetes controllers, to allow the system to function. It is a flat repo of network policies, with a dev/prod split done with two branches and kustomization.yaml files to include/exclude network policies depending on the environment. See also: - The namespace-controller for the full set of default policies - The profiles-controller also creates network policies in kubeflow-profile namespaces Network Policies Network Policies are a Layer 4 (transport layer) firewall tool for managing flow between pods/namespaces based on labels/selectors and ip ranges. When combined with the immutable label contraints this enables parts of the protected-b implementation, by allowing policies to apply selectively to a data.statcan.gc.ca/classification label, which may be either unlcassified or protected-b . You typically always have a matching Ingress and Egress NetworkPolicy in the recieving and sending namespaces (respectively). The senders are often (but not always) Notebooks, which you should refer to the profiles-controller for more on. Default per-namespace Network Policies Default-Deny + Allow-Same-Namespace The philosophy in the AAW is \"Default Deny; explicit Allow\". There is a namespace-controller which creates a few default policies; among which is default-deny along with allow-same-ns for allowing traffic in the namespace (among non-protected-b pods). All Kubeflow Profiles are configured by the profiles-controller The profiles-controller also creates network policies in kubeflow-profile namespaces. For example, every kubeflow profile namespace will get a NetworkPolicy added to allow notebooks to talk to Artifactory, as well as rules to talk to Protected-B and non-protected-b MinIO. Implementation & Known Issues IPTables are slow At the time of writing the Azure-NPM is iptables based, which has led to serious performance issues . Some alternative implementations of NetworkPolicies use eBPF, which claim to offer better performance. Lots of Network Policies Network Policies are a namespaced resource, which means that, when creating N policies in M Kubeflow-Profile namespaces, you get N\u00d7M policies, which can result in slow network-policy reconciliation times as well as performance issues reconfiguring the firewalls (as mentioned above). One possible solution for this issue is to explore non-standard alternatives such as Clilium's CiliunClusterwideNetworkPolicy s , which would avoid this issue. It would also remove the need for two kubernetes controllers, namespace-controller --network and profiles-controller --network .","title":"Network Policies"},{"location":"daaas-system/network-policies/#network-policies","text":"Network Policies are a Layer 4 (transport layer) firewall tool for managing flow between pods/namespaces based on labels/selectors and ip ranges. When combined with the immutable label contraints this enables parts of the protected-b implementation, by allowing policies to apply selectively to a data.statcan.gc.ca/classification label, which may be either unlcassified or protected-b . You typically always have a matching Ingress and Egress NetworkPolicy in the recieving and sending namespaces (respectively). The senders are often (but not always) Notebooks, which you should refer to the profiles-controller for more on.","title":"Network Policies"},{"location":"daaas-system/network-policies/#default-per-namespace-network-policies","text":"","title":"Default per-namespace Network Policies"},{"location":"daaas-system/network-policies/#default-deny-allow-same-namespace","text":"The philosophy in the AAW is \"Default Deny; explicit Allow\". There is a namespace-controller which creates a few default policies; among which is default-deny along with allow-same-ns for allowing traffic in the namespace (among non-protected-b pods).","title":"Default-Deny + Allow-Same-Namespace"},{"location":"daaas-system/network-policies/#all-kubeflow-profiles-are-configured-by-the-profiles-controller","text":"The profiles-controller also creates network policies in kubeflow-profile namespaces. For example, every kubeflow profile namespace will get a NetworkPolicy added to allow notebooks to talk to Artifactory, as well as rules to talk to Protected-B and non-protected-b MinIO.","title":"All Kubeflow Profiles are configured by the profiles-controller"},{"location":"daaas-system/network-policies/#implementation-known-issues","text":"","title":"Implementation &amp; Known Issues"},{"location":"daaas-system/network-policies/#iptables-are-slow","text":"At the time of writing the Azure-NPM is iptables based, which has led to serious performance issues . Some alternative implementations of NetworkPolicies use eBPF, which claim to offer better performance.","title":"IPTables are slow"},{"location":"daaas-system/network-policies/#lots-of-network-policies","text":"Network Policies are a namespaced resource, which means that, when creating N policies in M Kubeflow-Profile namespaces, you get N\u00d7M policies, which can result in slow network-policy reconciliation times as well as performance issues reconfiguring the firewalls (as mentioned above). One possible solution for this issue is to explore non-standard alternatives such as Clilium's CiliunClusterwideNetworkPolicy s , which would avoid this issue. It would also remove the need for two kubernetes controllers, namespace-controller --network and profiles-controller --network .","title":"Lots of Network Policies"},{"location":"daaas-system/notebook-controllers/","text":"Notebook Controllers We use notebook controllers both to: Add functionality, such as adding credentials or volume mounts Apply custom networking, such as dynamic authorization policies to block endpoints. Examples of (1) are the goofys and minio-credential injectors (in fact, likely any injector is in this category), and an example of (2) is the auth-policy-checker , which creates the Istio AuthorizationPolicy object on protected-b notebooks to block upload and download functionalities.","title":"Notebook Controllers"},{"location":"daaas-system/notebook-controllers/#notebook-controllers","text":"We use notebook controllers both to: Add functionality, such as adding credentials or volume mounts Apply custom networking, such as dynamic authorization policies to block endpoints. Examples of (1) are the goofys and minio-credential injectors (in fact, likely any injector is in this category), and an example of (2) is the auth-policy-checker , which creates the Istio AuthorizationPolicy object on protected-b notebooks to block upload and download functionalities.","title":"Notebook Controllers"},{"location":"daaas-system/notebook-controllers/goofys-injector/","text":"Goofys Injector Inject MinIO volume configuration using goofys into Jupyter Notebook pods.","title":"Goofys Injector"},{"location":"daaas-system/notebook-controllers/goofys-injector/#goofys-injector","text":"Inject MinIO volume configuration using goofys into Jupyter Notebook pods.","title":"Goofys Injector"},{"location":"daaas-system/notebook-controllers/minio-credential-injector/","text":"minio-credential-injector This mutating webhook adds minio credential annotations to notebook pods and argo workflows (used by Kubeflow Pipelines). To configure use with different instances, put a instances.json file in the working directory. For example {\"name\": \"minio_standard\", \"classification\": \"unclassified\", \"serviceUrl\": \"http://minio.minio-standard-system:443\"} {\"name\": \"minio_premium\", \"classification\": \"unclassified\", \"serviceUrl\": \"http://minio.minio-premium-system:443\"} Try it with ./minio-credential-injector & curl --insecure -X POST -H \"Content-Type: application/json\" \\ -d @samples/pod.json https://0.0.0.0:8443/mutate | jq -r '.response.patch | @base64d' | jq","title":"minio-credential-injector"},{"location":"daaas-system/notebook-controllers/minio-credential-injector/#minio-credential-injector","text":"This mutating webhook adds minio credential annotations to notebook pods and argo workflows (used by Kubeflow Pipelines). To configure use with different instances, put a instances.json file in the working directory. For example {\"name\": \"minio_standard\", \"classification\": \"unclassified\", \"serviceUrl\": \"http://minio.minio-standard-system:443\"} {\"name\": \"minio_premium\", \"classification\": \"unclassified\", \"serviceUrl\": \"http://minio.minio-premium-system:443\"} Try it with ./minio-credential-injector & curl --insecure -X POST -H \"Content-Type: application/json\" \\ -d @samples/pod.json https://0.0.0.0:8443/mutate | jq -r '.response.patch | @base64d' | jq","title":"minio-credential-injector"},{"location":"daaas-system/notebook-controllers/notebook-auth-policy-checker/","text":"Blocking Upload and Download Note: Needs to be used in conjunction with the gatekeeper constraint . Otherwise the pod may start before the auth policy is in place, allowing unauthorized actions. Link: protected-b-notebook-controller (Fran\u00e7ais) Prob Notebook Controller Based on https://github.com/StatCan/kubeflow-controller There is a dependency on that repository as well since it needs to be imported in order to use the Notebook struct and NotebookInformer . This controller creates and deletes Authorization Policies based on Notebooks. The Authorization Policies block uploads and downloads on jupyterlab and rstudio images. How to use Go check the README in the kind folder for instruction on running it locally. How to Contribute See CONTRIBUTING.md License Unless otherwise noted, the source code of this project is covered under Crown Copyright, Government of Canada, and is distributed under the MIT License . The Canada wordmark and related graphics associated with this distribution are protected under trademark law and copyright law. No permission is granted to use them outside the parameters of the Government of Canada's corporate identity program. For more information, see Federal identity requirements . Contr\u00f4leur bloc-note prob Bas\u00e9 sur https://github.com/StatCan/kubeflow-controller Il y a une d\u00e9pendance sur ce r\u00e9pertoire puique certains de ses \u00e9l\u00e9ments sont import\u00e9s de fa\u00e7on a utilis\u00e9 la structure Notebook et NotebookInformer . Ce controller cr\u00e9er et supprime les Authorization Policies bas\u00e9es sur les Noteboks. Les Authorization Pol;icies bloquent les t\u00e9l\u00e9chargement ou t\u00e9l\u00e9versment de sur les image de jupyterlab et rstudio. Comment utiliser Aller voir le README dans le dossier kind pour les instructions pour l'ex\u00e9cution locale. Comment contribuer Voir CONTRIBUTING.md Licence Sauf indication contraire, le code source de ce projet est prot\u00e9g\u00e9 par le droit d'auteur de la Couronne du gouvernement du Canada et distribu\u00e9 sous la licence MIT . Le mot-symbole \u00ab Canada \u00bb et les \u00e9l\u00e9ments graphiques connexes li\u00e9s \u00e0 cette distribution sont prot\u00e9g\u00e9s en vertu des lois portant sur les marques de commerce et le droit d'auteur. Aucune autorisation n'est accord\u00e9e pour leur utilisation \u00e0 l'ext\u00e9rieur des param\u00e8tres du programme de coordination de l'image de marque du gouvernement du Canada. Pour obtenir davantage de renseignements \u00e0 ce sujet, veuillez consulter les Exigences pour l'image de marque .","title":"Blocking Upload and Download"},{"location":"daaas-system/notebook-controllers/notebook-auth-policy-checker/#blocking-upload-and-download","text":"Note: Needs to be used in conjunction with the gatekeeper constraint . Otherwise the pod may start before the auth policy is in place, allowing unauthorized actions. Link: protected-b-notebook-controller (Fran\u00e7ais)","title":"Blocking Upload and Download"},{"location":"daaas-system/notebook-controllers/notebook-auth-policy-checker/#prob-notebook-controller","text":"Based on https://github.com/StatCan/kubeflow-controller There is a dependency on that repository as well since it needs to be imported in order to use the Notebook struct and NotebookInformer . This controller creates and deletes Authorization Policies based on Notebooks. The Authorization Policies block uploads and downloads on jupyterlab and rstudio images.","title":"Prob Notebook Controller"},{"location":"daaas-system/notebook-controllers/notebook-auth-policy-checker/#how-to-use","text":"Go check the README in the kind folder for instruction on running it locally.","title":"How to use"},{"location":"daaas-system/notebook-controllers/notebook-auth-policy-checker/#how-to-contribute","text":"See CONTRIBUTING.md","title":"How to Contribute"},{"location":"daaas-system/notebook-controllers/notebook-auth-policy-checker/#license","text":"Unless otherwise noted, the source code of this project is covered under Crown Copyright, Government of Canada, and is distributed under the MIT License . The Canada wordmark and related graphics associated with this distribution are protected under trademark law and copyright law. No permission is granted to use them outside the parameters of the Government of Canada's corporate identity program. For more information, see Federal identity requirements .","title":"License"},{"location":"daaas-system/notebook-controllers/notebook-auth-policy-checker/#controleur-bloc-note-prob","text":"Bas\u00e9 sur https://github.com/StatCan/kubeflow-controller Il y a une d\u00e9pendance sur ce r\u00e9pertoire puique certains de ses \u00e9l\u00e9ments sont import\u00e9s de fa\u00e7on a utilis\u00e9 la structure Notebook et NotebookInformer . Ce controller cr\u00e9er et supprime les Authorization Policies bas\u00e9es sur les Noteboks. Les Authorization Pol;icies bloquent les t\u00e9l\u00e9chargement ou t\u00e9l\u00e9versment de sur les image de jupyterlab et rstudio.","title":"Contr\u00f4leur bloc-note prob"},{"location":"daaas-system/notebook-controllers/notebook-auth-policy-checker/#comment-utiliser","text":"Aller voir le README dans le dossier kind pour les instructions pour l'ex\u00e9cution locale.","title":"Comment utiliser"},{"location":"daaas-system/notebook-controllers/notebook-auth-policy-checker/#comment-contribuer","text":"Voir CONTRIBUTING.md","title":"Comment contribuer"},{"location":"daaas-system/notebook-controllers/notebook-auth-policy-checker/#licence","text":"Sauf indication contraire, le code source de ce projet est prot\u00e9g\u00e9 par le droit d'auteur de la Couronne du gouvernement du Canada et distribu\u00e9 sous la licence MIT . Le mot-symbole \u00ab Canada \u00bb et les \u00e9l\u00e9ments graphiques connexes li\u00e9s \u00e0 cette distribution sont prot\u00e9g\u00e9s en vertu des lois portant sur les marques de commerce et le droit d'auteur. Aucune autorisation n'est accord\u00e9e pour leur utilisation \u00e0 l'ext\u00e9rieur des param\u00e8tres du programme de coordination de l'image de marque du gouvernement du Canada. Pour obtenir davantage de renseignements \u00e0 ce sujet, veuillez consulter les Exigences pour l'image de marque .","title":"Licence"},{"location":"daaas-system/profile-controllers/","text":"The kubeflow-controller was our original mechanism for adding per-profile resources across namespaces. We regret its original design, as it became a large, monolithic system, which made it progressively harder to test and develop. We are moving to a refactored design, the profiles-controller , which factors the controllers into separate modules which execute independently. The monolithic kubeflow-controller will eventually be removed.","title":"Profiles Controller"},{"location":"daaas-system/profile-controllers/kubeflow-controller/","text":"kubeflow-controller kubeflow-controller This repository implements a simple controller for watching Profile resources as defined with a CustomResourceDefinition (CRD). Note: go-get or vendor this package as github.com/StatCan/kubeflow-controller . This particular example demonstrates how to perform basic operations such as: How to register a new custom resource (custom resource type) of type Profile using a CustomResourceDefinition. How to create/get/list instances of your new resource type Profile . How to setup a controller on resource handling create/update/delete events. It makes use of the generators in k8s.io/code-generator to generate a typed client, informers, listers and deep-copy functions. You can do this yourself using the ./hack/update-codegen.sh script. The update-codegen script will automatically generate the following files & directories: pkg/apis/kubeflowcontroller/v1/zz_generated.deepcopy.go pkg/generated/ Changes should not be made to these files manually, and when creating your own controller based off of this implementation you should not copy these files and instead run the update-codegen script to generate your own. Details The kubeflow controller uses client-go library extensively. The details of interaction points of the kubeflow controller with various mechanisms from this library are explained here . Fetch kubeflow-controller and its dependencies Like the rest of Kubernetes, kubeflow-controller has used godep and $GOPATH for years and is now adopting go 1.11 modules. There are thus two alternative ways to go about fetching this demo and its dependencies. Fetch with godep When NOT using go 1.11 modules, you can use the following commands. go get -d github.com/StatCan/kubeflow-controller cd $GOPATH/src/github.com/StatCan/kubeflow-controller godep restore When using go 1.11 modules When using go 1.11 modules ( GO111MODULE=on ), issue the following commands --- starting in whatever working directory you like. git clone https://github.com/statcan/kubeflow-controller.git cd kubeflow-controller Note, however, that if you intend to generate code then you will also need the code-generator repo to exist in an old-style location. One easy way to do this is to use the command go mod vendor to create and populate the vendor directory. Purpose This controller updates the state of Vault to allow access to secrets from OIDC users and from inside a profile's namespace. Running Prerequisite : Since the kubeflow-controller uses apps/v1 deployments, the Kubernetes cluster version should be greater than 1.9. # assumes you have a working kubeconfig, not required if operating in-cluster go build -o kubeflow-controller . ./kubeflow-controller -kubeconfig=$HOME/.kube/config # create a CustomResourceDefinition kubectl create -f artifacts/examples/crd.yaml # create a custom resource of type Profile kubectl create -f artifacts/examples/example-profile.yaml # check deployments created through the custom resource kubectl get deployments Use Cases CustomResourceDefinitions can be used to implement custom resource types for your Kubernetes cluster. These act like most other Resources in Kubernetes, and may be kubectl apply 'd, etc. Some example use cases: Provisioning/Management of external datastores/databases (eg. CloudSQL/RDS instances) Higher level abstractions around Kubernetes primitives (eg. a single Resource to define an etcd cluster, backed by a Service and a ReplicationController) Cleanup You can clean up the created CustomResourceDefinition with: kubectl delete crd profiles.kubeflow.org","title":"Index"},{"location":"daaas-system/profile-controllers/kubeflow-controller/#kubeflow-controller","text":"This repository implements a simple controller for watching Profile resources as defined with a CustomResourceDefinition (CRD). Note: go-get or vendor this package as github.com/StatCan/kubeflow-controller . This particular example demonstrates how to perform basic operations such as: How to register a new custom resource (custom resource type) of type Profile using a CustomResourceDefinition. How to create/get/list instances of your new resource type Profile . How to setup a controller on resource handling create/update/delete events. It makes use of the generators in k8s.io/code-generator to generate a typed client, informers, listers and deep-copy functions. You can do this yourself using the ./hack/update-codegen.sh script. The update-codegen script will automatically generate the following files & directories: pkg/apis/kubeflowcontroller/v1/zz_generated.deepcopy.go pkg/generated/ Changes should not be made to these files manually, and when creating your own controller based off of this implementation you should not copy these files and instead run the update-codegen script to generate your own.","title":"kubeflow-controller"},{"location":"daaas-system/profile-controllers/kubeflow-controller/#details","text":"The kubeflow controller uses client-go library extensively. The details of interaction points of the kubeflow controller with various mechanisms from this library are explained here .","title":"Details"},{"location":"daaas-system/profile-controllers/kubeflow-controller/#fetch-kubeflow-controller-and-its-dependencies","text":"Like the rest of Kubernetes, kubeflow-controller has used godep and $GOPATH for years and is now adopting go 1.11 modules. There are thus two alternative ways to go about fetching this demo and its dependencies.","title":"Fetch kubeflow-controller and its dependencies"},{"location":"daaas-system/profile-controllers/kubeflow-controller/#fetch-with-godep","text":"When NOT using go 1.11 modules, you can use the following commands. go get -d github.com/StatCan/kubeflow-controller cd $GOPATH/src/github.com/StatCan/kubeflow-controller godep restore","title":"Fetch with godep"},{"location":"daaas-system/profile-controllers/kubeflow-controller/#when-using-go-111-modules","text":"When using go 1.11 modules ( GO111MODULE=on ), issue the following commands --- starting in whatever working directory you like. git clone https://github.com/statcan/kubeflow-controller.git cd kubeflow-controller Note, however, that if you intend to generate code then you will also need the code-generator repo to exist in an old-style location. One easy way to do this is to use the command go mod vendor to create and populate the vendor directory.","title":"When using go 1.11 modules"},{"location":"daaas-system/profile-controllers/kubeflow-controller/#purpose","text":"This controller updates the state of Vault to allow access to secrets from OIDC users and from inside a profile's namespace.","title":"Purpose"},{"location":"daaas-system/profile-controllers/kubeflow-controller/#running","text":"Prerequisite : Since the kubeflow-controller uses apps/v1 deployments, the Kubernetes cluster version should be greater than 1.9. # assumes you have a working kubeconfig, not required if operating in-cluster go build -o kubeflow-controller . ./kubeflow-controller -kubeconfig=$HOME/.kube/config # create a CustomResourceDefinition kubectl create -f artifacts/examples/crd.yaml # create a custom resource of type Profile kubectl create -f artifacts/examples/example-profile.yaml # check deployments created through the custom resource kubectl get deployments","title":"Running"},{"location":"daaas-system/profile-controllers/kubeflow-controller/#use-cases","text":"CustomResourceDefinitions can be used to implement custom resource types for your Kubernetes cluster. These act like most other Resources in Kubernetes, and may be kubectl apply 'd, etc. Some example use cases: Provisioning/Management of external datastores/databases (eg. CloudSQL/RDS instances) Higher level abstractions around Kubernetes primitives (eg. a single Resource to define an etcd cluster, backed by a Service and a ReplicationController)","title":"Use Cases"},{"location":"daaas-system/profile-controllers/kubeflow-controller/#cleanup","text":"You can clean up the created CustomResourceDefinition with: kubectl delete crd profiles.kubeflow.org","title":"Cleanup"},{"location":"daaas-system/profile-controllers/profiles-controller/","text":"profiles-controller profiles-controller This repository implements a simple controller for watching Foo resources as defined with a CustomResourceDefinition (CRD). Note: go-get or vendor this package as k8s.io/profiles-controller . This particular example demonstrates how to perform basic operations such as: How to register a new custom resource (custom resource type) of type Foo using a CustomResourceDefinition. How to create/get/list instances of your new resource type Foo . How to setup a controller on resource handling create/update/delete events. It makes use of the generators in k8s.io/code-generator to generate a typed client, informers, listers and deep-copy functions. You can do this yourself using the ./hack/update-codegen.sh script. The update-codegen script will automatically generate the following files & directories: pkg/apis/profilescontroller/v1alpha1/zz_generated.deepcopy.go pkg/generated/ Changes should not be made to these files manually, and when creating your own controller based off of this implementation you should not copy these files and instead run the update-codegen script to generate your own. Details The profiles controller uses client-go library extensively. The details of interaction points of the profiles controller with various mechanisms from this library are explained here . Fetch profiles-controller and its dependencies Like the rest of Kubernetes, profiles-controller has used godep and $GOPATH for years and is now adopting go 1.11 modules. There are thus two alternative ways to go about fetching this demo and its dependencies. Fetch with godep When NOT using go 1.11 modules, you can use the following commands. go get -d k8s.io/profiles-controller cd $GOPATH/src/k8s.io/profiles-controller godep restore When using go 1.11 modules When using go 1.11 modules ( GO111MODULE=on ), issue the following commands --- starting in whatever working directory you like. git clone https://github.com/kubernetes/profiles-controller.git cd profiles-controller Note, however, that if you intend to generate code then you will also need the code-generator repo to exist in an old-style location. One easy way to do this is to use the command go mod vendor to create and populate the vendor directory. A Note on kubernetes/kubernetes If you are developing Kubernetes according to https://github.com/kubernetes/community/blob/master/contributors/guide/github-workflow.md then you already have a copy of this demo in kubernetes/staging/src/k8s.io/profiles-controller and its dependencies --- including the code generator --- are in usable locations (valid for all Go versions). Purpose This is an example of how to build a kube-like controller with a single type. Running Prerequisite : Since the profiles-controller uses apps/v1 deployments, the Kubernetes cluster version should be greater than 1.9. # assumes you have a working kubeconfig, not required if operating in-cluster go build -o profiles-controller . ./profiles-controller -kubeconfig=$HOME/.kube/config # create a CustomResourceDefinition kubectl create -f artifacts/examples/crd.yaml # create a custom resource of type Foo kubectl create -f artifacts/examples/example-foo.yaml # check deployments created through the custom resource kubectl get deployments Use Cases CustomResourceDefinitions can be used to implement custom resource types for your Kubernetes cluster. These act like most other Resources in Kubernetes, and may be kubectl apply 'd, etc. Some example use cases: Provisioning/Management of external datastores/databases (eg. CloudSQL/RDS instances) Higher level abstractions around Kubernetes primitives (eg. a single Resource to define an etcd cluster, backed by a Service and a ReplicationController) Defining types Each instance of your custom resource has an attached Spec, which should be defined via a struct{} to provide data format validation. In practice, this Spec is arbitrary key-value data that specifies the configuration/behavior of your Resource. For example, if you were implementing a custom resource for a Database, you might provide a DatabaseSpec like the following: type DatabaseSpec struct { Databases []string `json:\"databases\"` Users []User `json:\"users\"` Version string `json:\"version\"` } type User struct { Name string `json:\"name\"` Password string `json:\"password\"` } Validation To validate custom resources, use the CustomResourceValidation feature. Validation in the form of a structured schema is mandatory to be provided for apiextensions.k8s.io/v1 . Example The schema in crd.yaml applies the following validation on the custom resource: spec.replicas must be an integer and must have a minimum value of 1 and a maximum value of 10. Subresources Custom Resources support /status and /scale subresources . The CustomResourceSubresources feature is in GA from v1.16. Example The CRD in crd-status-subresource.yaml enables the /status subresource for custom resources. This means that UpdateStatus can be used by the controller to update only the status part of the custom resource. To understand why only the status part of the custom resource should be updated, please refer to the Kubernetes API conventions . In the above steps, use crd-status-subresource.yaml to create the CRD: # create a CustomResourceDefinition supporting the status subresource kubectl create -f artifacts/examples/crd-status-subresource.yaml A Note on the API version The group version of the custom resource in crd.yaml is v1alpha , this can be evolved to a stable API version, v1 , using CRD Versioning . Cleanup You can clean up the created CustomResourceDefinition with: kubectl delete crd foos.profilescontroller.k8s.io Compatibility HEAD of this repository will match HEAD of k8s.io/apimachinery and k8s.io/client-go. Where does it come from? profiles-controller is synced from https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/sample-controller. Code changes are made in that location, merged into k8s.io/kubernetes and later synced here.","title":"Index"},{"location":"daaas-system/profile-controllers/profiles-controller/#profiles-controller","text":"This repository implements a simple controller for watching Foo resources as defined with a CustomResourceDefinition (CRD). Note: go-get or vendor this package as k8s.io/profiles-controller . This particular example demonstrates how to perform basic operations such as: How to register a new custom resource (custom resource type) of type Foo using a CustomResourceDefinition. How to create/get/list instances of your new resource type Foo . How to setup a controller on resource handling create/update/delete events. It makes use of the generators in k8s.io/code-generator to generate a typed client, informers, listers and deep-copy functions. You can do this yourself using the ./hack/update-codegen.sh script. The update-codegen script will automatically generate the following files & directories: pkg/apis/profilescontroller/v1alpha1/zz_generated.deepcopy.go pkg/generated/ Changes should not be made to these files manually, and when creating your own controller based off of this implementation you should not copy these files and instead run the update-codegen script to generate your own.","title":"profiles-controller"},{"location":"daaas-system/profile-controllers/profiles-controller/#details","text":"The profiles controller uses client-go library extensively. The details of interaction points of the profiles controller with various mechanisms from this library are explained here .","title":"Details"},{"location":"daaas-system/profile-controllers/profiles-controller/#fetch-profiles-controller-and-its-dependencies","text":"Like the rest of Kubernetes, profiles-controller has used godep and $GOPATH for years and is now adopting go 1.11 modules. There are thus two alternative ways to go about fetching this demo and its dependencies.","title":"Fetch profiles-controller and its dependencies"},{"location":"daaas-system/profile-controllers/profiles-controller/#fetch-with-godep","text":"When NOT using go 1.11 modules, you can use the following commands. go get -d k8s.io/profiles-controller cd $GOPATH/src/k8s.io/profiles-controller godep restore","title":"Fetch with godep"},{"location":"daaas-system/profile-controllers/profiles-controller/#when-using-go-111-modules","text":"When using go 1.11 modules ( GO111MODULE=on ), issue the following commands --- starting in whatever working directory you like. git clone https://github.com/kubernetes/profiles-controller.git cd profiles-controller Note, however, that if you intend to generate code then you will also need the code-generator repo to exist in an old-style location. One easy way to do this is to use the command go mod vendor to create and populate the vendor directory.","title":"When using go 1.11 modules"},{"location":"daaas-system/profile-controllers/profiles-controller/#a-note-on-kuberneteskubernetes","text":"If you are developing Kubernetes according to https://github.com/kubernetes/community/blob/master/contributors/guide/github-workflow.md then you already have a copy of this demo in kubernetes/staging/src/k8s.io/profiles-controller and its dependencies --- including the code generator --- are in usable locations (valid for all Go versions).","title":"A Note on kubernetes/kubernetes"},{"location":"daaas-system/profile-controllers/profiles-controller/#purpose","text":"This is an example of how to build a kube-like controller with a single type.","title":"Purpose"},{"location":"daaas-system/profile-controllers/profiles-controller/#running","text":"Prerequisite : Since the profiles-controller uses apps/v1 deployments, the Kubernetes cluster version should be greater than 1.9. # assumes you have a working kubeconfig, not required if operating in-cluster go build -o profiles-controller . ./profiles-controller -kubeconfig=$HOME/.kube/config # create a CustomResourceDefinition kubectl create -f artifacts/examples/crd.yaml # create a custom resource of type Foo kubectl create -f artifacts/examples/example-foo.yaml # check deployments created through the custom resource kubectl get deployments","title":"Running"},{"location":"daaas-system/profile-controllers/profiles-controller/#use-cases","text":"CustomResourceDefinitions can be used to implement custom resource types for your Kubernetes cluster. These act like most other Resources in Kubernetes, and may be kubectl apply 'd, etc. Some example use cases: Provisioning/Management of external datastores/databases (eg. CloudSQL/RDS instances) Higher level abstractions around Kubernetes primitives (eg. a single Resource to define an etcd cluster, backed by a Service and a ReplicationController)","title":"Use Cases"},{"location":"daaas-system/profile-controllers/profiles-controller/#defining-types","text":"Each instance of your custom resource has an attached Spec, which should be defined via a struct{} to provide data format validation. In practice, this Spec is arbitrary key-value data that specifies the configuration/behavior of your Resource. For example, if you were implementing a custom resource for a Database, you might provide a DatabaseSpec like the following: type DatabaseSpec struct { Databases []string `json:\"databases\"` Users []User `json:\"users\"` Version string `json:\"version\"` } type User struct { Name string `json:\"name\"` Password string `json:\"password\"` }","title":"Defining types"},{"location":"daaas-system/profile-controllers/profiles-controller/#validation","text":"To validate custom resources, use the CustomResourceValidation feature. Validation in the form of a structured schema is mandatory to be provided for apiextensions.k8s.io/v1 .","title":"Validation"},{"location":"daaas-system/profile-controllers/profiles-controller/#example","text":"The schema in crd.yaml applies the following validation on the custom resource: spec.replicas must be an integer and must have a minimum value of 1 and a maximum value of 10.","title":"Example"},{"location":"daaas-system/profile-controllers/profiles-controller/#subresources","text":"Custom Resources support /status and /scale subresources . The CustomResourceSubresources feature is in GA from v1.16.","title":"Subresources"},{"location":"daaas-system/profile-controllers/profiles-controller/#example_1","text":"The CRD in crd-status-subresource.yaml enables the /status subresource for custom resources. This means that UpdateStatus can be used by the controller to update only the status part of the custom resource. To understand why only the status part of the custom resource should be updated, please refer to the Kubernetes API conventions . In the above steps, use crd-status-subresource.yaml to create the CRD: # create a CustomResourceDefinition supporting the status subresource kubectl create -f artifacts/examples/crd-status-subresource.yaml","title":"Example"},{"location":"daaas-system/profile-controllers/profiles-controller/#a-note-on-the-api-version","text":"The group version of the custom resource in crd.yaml is v1alpha , this can be evolved to a stable API version, v1 , using CRD Versioning .","title":"A Note on the API version"},{"location":"daaas-system/profile-controllers/profiles-controller/#cleanup","text":"You can clean up the created CustomResourceDefinition with: kubectl delete crd foos.profilescontroller.k8s.io","title":"Cleanup"},{"location":"daaas-system/profile-controllers/profiles-controller/#compatibility","text":"HEAD of this repository will match HEAD of k8s.io/apimachinery and k8s.io/client-go.","title":"Compatibility"},{"location":"daaas-system/profile-controllers/profiles-controller/#where-does-it-come-from","text":"profiles-controller is synced from https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/sample-controller. Code changes are made in that location, merged into k8s.io/kubernetes and later synced here.","title":"Where does it come from?"},{"location":"daaas-system/workflows-cronjob/","text":"Cleanup old workflows This cronjob just cleans up the resources left from old Argo Workflows","title":"Cleanup old workflows"},{"location":"daaas-system/workflows-cronjob/#cleanup-old-workflows","text":"This cronjob just cleans up the resources left from old Argo Workflows","title":"Cleanup old workflows"},{"location":"statcan-system/gatekeeper/","text":"Gatekeeper Policies & Constraints The Gatekeeper Policies repo is a collection of ConstraintTemplate s, which are instatiated in the (private) Gatekeeper Constraints Repo . NOTE: Gatekeeper has a global configmap of all resources it can watch. Example . If you add policies/constraints you may need to edit this too. GateKeeper Policies Policies that are to be enforced by GateKeeper for the Kubernetes Platform. Note: Gatekeeper is a validating / mutating webhook that enforces CRD-based policies executed by the Open Policy Agent. General This repo contains general policies that can be used to enforce common Kubernetes requirements. Control Aspect Gatekeeper Constraint Template Container Allowed Images container-allowed-images Container Image Must Have Digest container-image-must-have-digest Container Limits container-limits Ingress No Hostnames ingress-no-hostnames Ingress Hostnames Conflict ingress-hostnames-conflict Load Balancer No Public IPs loadbalancer-no-public-ips Pod Enforce Labels pod-enforce-labels Pod Security Policies This repo contains common policies replacing the deprecated PodSecurityPolicy into Constraint Templates using GateKeeper . Control Aspect Gatekeeper Constraint Template Allowed external ips allowed-external-ips Allowed host paths allowed-host-paths Allowed privilege escalation allowed-privilege-escalation Allowed proc mount types allowed-proc-mount-types Allowed seccomp profiles allowed-seccomp-profiles Allowed users and groups allowed-users-groups Allowed volume types allowed-volume-types Block automount token block-automount-token Block default namespace block-default-namespace Block host namespace block-host-namespace Container capabilities container-capabilities Container no privilege escalation container-no-privilege-escalation Deny extraction deny-extraction Deny pipelines deny-pipelines Disk data classification disk-data-classification Enforce apparmor profile enforce-apparmor-profile Flexvolume drivers flexvolume-drivers Forbidden sysctls forbidden-sysctls Host networking and ports host-network-ports Protected B Auth protectedb-auth Require read only root file system read-only-root-filesystem Metadata restrictions metadata-restrictions Namespace guardrails namespace-guardrails SELinux context of the container seLinux Service Mesh This repo contains a set of common policies that can be used to enforce specific Service Mesh features. Control Aspect Gatekeeper Constraint Template Gateway gateway Peer Authentication peer-authentication Port Naming port-naming Traffic Policy traffic-policy Links Rego Playground Acknowledgements Anthos Azure Policy Community Policy Open Policy Agent","title":"Gatekeeper Policies & Constraints"},{"location":"statcan-system/gatekeeper/#gatekeeper-policies-constraints","text":"The Gatekeeper Policies repo is a collection of ConstraintTemplate s, which are instatiated in the (private) Gatekeeper Constraints Repo . NOTE: Gatekeeper has a global configmap of all resources it can watch. Example . If you add policies/constraints you may need to edit this too.","title":"Gatekeeper Policies &amp; Constraints"},{"location":"statcan-system/gatekeeper/#gatekeeper-policies","text":"Policies that are to be enforced by GateKeeper for the Kubernetes Platform. Note: Gatekeeper is a validating / mutating webhook that enforces CRD-based policies executed by the Open Policy Agent.","title":"GateKeeper Policies"},{"location":"statcan-system/gatekeeper/#general","text":"This repo contains general policies that can be used to enforce common Kubernetes requirements. Control Aspect Gatekeeper Constraint Template Container Allowed Images container-allowed-images Container Image Must Have Digest container-image-must-have-digest Container Limits container-limits Ingress No Hostnames ingress-no-hostnames Ingress Hostnames Conflict ingress-hostnames-conflict Load Balancer No Public IPs loadbalancer-no-public-ips Pod Enforce Labels pod-enforce-labels","title":"General"},{"location":"statcan-system/gatekeeper/#pod-security-policies","text":"This repo contains common policies replacing the deprecated PodSecurityPolicy into Constraint Templates using GateKeeper . Control Aspect Gatekeeper Constraint Template Allowed external ips allowed-external-ips Allowed host paths allowed-host-paths Allowed privilege escalation allowed-privilege-escalation Allowed proc mount types allowed-proc-mount-types Allowed seccomp profiles allowed-seccomp-profiles Allowed users and groups allowed-users-groups Allowed volume types allowed-volume-types Block automount token block-automount-token Block default namespace block-default-namespace Block host namespace block-host-namespace Container capabilities container-capabilities Container no privilege escalation container-no-privilege-escalation Deny extraction deny-extraction Deny pipelines deny-pipelines Disk data classification disk-data-classification Enforce apparmor profile enforce-apparmor-profile Flexvolume drivers flexvolume-drivers Forbidden sysctls forbidden-sysctls Host networking and ports host-network-ports Protected B Auth protectedb-auth Require read only root file system read-only-root-filesystem Metadata restrictions metadata-restrictions Namespace guardrails namespace-guardrails SELinux context of the container seLinux","title":"Pod Security Policies"},{"location":"statcan-system/gatekeeper/#service-mesh","text":"This repo contains a set of common policies that can be used to enforce specific Service Mesh features. Control Aspect Gatekeeper Constraint Template Gateway gateway Peer Authentication peer-authentication Port Naming port-naming Traffic Policy traffic-policy","title":"Service Mesh"},{"location":"statcan-system/gatekeeper/#links","text":"Rego Playground","title":"Links"},{"location":"statcan-system/gatekeeper/#acknowledgements","text":"Anthos Azure Policy Community Policy Open Policy Agent","title":"Acknowledgements"},{"location":"statcan-system/sidecar-terminator/","text":"Note: Argo Workflows needs to use the emissary containerRuntimeExecutor in order for sidecar termination to work properly. This is because the pns executor uses a random pid . Link: Sidecar Terminator Why does this exist? Currently there is an issue when using sidecars (like istio-proxy) with jobs - they don't exit when the job has completed. This project will monitor those pods and then send a kill signal to the sidecar containers causing them to exit and the job to be marked as succeeded. How does it work? It will monitor all pods in the cluster, and terminate the sidecars if the following criteria has been met: The pod was created by a job The pod's non-sidecar containers have exited with exit code 0 Terminate occurs by executing into the sidecar container and running kill 1 . Getting started git clone https://github.com/zachomedia/kubernetes-sidecar-terminator.git kubectl apply -f manifests/","title":"Index"},{"location":"statcan-system/sidecar-terminator/#why-does-this-exist","text":"Currently there is an issue when using sidecars (like istio-proxy) with jobs - they don't exit when the job has completed. This project will monitor those pods and then send a kill signal to the sidecar containers causing them to exit and the job to be marked as succeeded.","title":"Why does this exist?"},{"location":"statcan-system/sidecar-terminator/#how-does-it-work","text":"It will monitor all pods in the cluster, and terminate the sidecars if the following criteria has been met: The pod was created by a job The pod's non-sidecar containers have exited with exit code 0 Terminate occurs by executing into the sidecar container and running kill 1 .","title":"How does it work?"},{"location":"statcan-system/sidecar-terminator/#getting-started","text":"git clone https://github.com/zachomedia/kubernetes-sidecar-terminator.git kubectl apply -f manifests/","title":"Getting started"},{"location":"statcan-system/toleration-injector/","text":"Toleration Injector (Fran\u00e7ais) DAaaS AAW Toleration Injector How to Contribute See CONTRIBUTING.md License Unless otherwise noted, the source code of this project is covered under Crown Copyright, Government of Canada, and is distributed under the MIT License . The Canada wordmark and related graphics associated with this distribution are protected under trademark law and copyright law. No permission is granted to use them outside the parameters of the Government of Canada's corporate identity program. For more information, see Federal identity requirements . Injecteur de Toleration pour ADS EAA Comment contribuer Voir CONTRIBUTING.md Licence Sauf indication contraire, le code source de ce projet est prot\u00e9g\u00e9 par le droit d'auteur de la Couronne du gouvernement du Canada et distribu\u00e9 sous la licence MIT . Le mot-symbole \u00ab Canada \u00bb et les \u00e9l\u00e9ments graphiques connexes li\u00e9s \u00e0 cette distribution sont prot\u00e9g\u00e9s en vertu des lois portant sur les marques de commerce et le droit d'auteur. Aucune autorisation n'est accord\u00e9e pour leur utilisation \u00e0 l'ext\u00e9rieur des param\u00e8tres du programme de coordination de l'image de marque du gouvernement du Canada. Pour obtenir davantage de renseignements \u00e0 ce sujet, veuillez consulter les Exigences pour l'image de marque .","title":"Toleration Injector"},{"location":"statcan-system/toleration-injector/#daaas-aaw-toleration-injector","text":"","title":"DAaaS AAW Toleration Injector"},{"location":"statcan-system/toleration-injector/#how-to-contribute","text":"See CONTRIBUTING.md","title":"How to Contribute"},{"location":"statcan-system/toleration-injector/#license","text":"Unless otherwise noted, the source code of this project is covered under Crown Copyright, Government of Canada, and is distributed under the MIT License . The Canada wordmark and related graphics associated with this distribution are protected under trademark law and copyright law. No permission is granted to use them outside the parameters of the Government of Canada's corporate identity program. For more information, see Federal identity requirements .","title":"License"},{"location":"statcan-system/toleration-injector/#injecteur-de-toleration-pour-ads-eaa","text":"","title":"Injecteur de Toleration pour ADS EAA"},{"location":"statcan-system/toleration-injector/#comment-contribuer","text":"Voir CONTRIBUTING.md","title":"Comment contribuer"},{"location":"statcan-system/toleration-injector/#licence","text":"Sauf indication contraire, le code source de ce projet est prot\u00e9g\u00e9 par le droit d'auteur de la Couronne du gouvernement du Canada et distribu\u00e9 sous la licence MIT . Le mot-symbole \u00ab Canada \u00bb et les \u00e9l\u00e9ments graphiques connexes li\u00e9s \u00e0 cette distribution sont prot\u00e9g\u00e9s en vertu des lois portant sur les marques de commerce et le droit d'auteur. Aucune autorisation n'est accord\u00e9e pour leur utilisation \u00e0 l'ext\u00e9rieur des param\u00e8tres du programme de coordination de l'image de marque du gouvernement du Canada. Pour obtenir davantage de renseignements \u00e0 ce sujet, veuillez consulter les Exigences pour l'image de marque .","title":"Licence"},{"location":"storage-system/kustomize-gateway/","text":"MinIO Gateway Each MinIO Gateway consists of MinIO + OPA + Etcd, with MinIO running in gateway mode, etcd acting as a cachefor the credentials, and OPA doing the policy enforcement. All except the OIDC flavour use Vault and the vault-minio-plugin for managing access/secret keys. There are four flavours of the gateway: Note: Only the OIDC version will have an Ingress. See notes below overlays/gateway-rw (Read-Write Vault Version) This version is the stock version, with OPA configuration to allow users to both read and write from MinIO. Note: This system will not have an Ingress object. This will only be accessed by an internal URL, which prevents tokens from being used from outside the cluster. overlays/gateway-ro (Read-Only Vault Version) This version is the stock version, with OPA configuration to only allow READ operations from users. The typical use-case here is to provide a read-only mirror of the data. For example, unclassified data can be made available as a read-only system to the protected-b notebooks, to allow use-cases like webscraping. Note: This system will not have an Ingress object. This will only be accessed by an internal URL, which prevents tokens from being used from outside the cluster. overlays/gateway-oidc (Read-Write OIDC Version) This version does not use Vault, but instead uses the kubeflow-opa-sync to get RoleBindings in the namespace. A user can connect to a bucket over OIDC if their username is assigned a contributor role in the namespace. overlays/gateway-bundle (Remotely Configured Vault Version) The bundle version refers to OPA Bundles , the use case here is when we are providing access to data within the cluster, but the allowed users and rules around the data is not determined by us. In this case, we are working with the FAIR Data Infrastructure team, who is responsible for the data and governance over it. Architecture Most aspects of the architecture are captured in the diagram below (which pictures a Vault version plus and OIDC version). Note that each MinIO gateway instance resides in a different namespace, mostly to avoid name conflicts as well as to be able to apply network policies at the namespace level. Notable aspects of the design: All instances live in their own namespace. This is to simplify name conflicts and network policies Expected use is to use the data.statcan.gc.ca/classification label on the namespace to restrict connections. Only the minio-gateway:9000 service in the namespace should be reachable by notebooks. Vault needs access to all namespaces (except the OIDC setup). All need to be able to connect to Azure. Many systems share one storage account. A single \"tenant\" could have a readwrite , readonly , and oidc instance, to allow Unclassified Notebook Access , Protected-B Notebook Access , and Web-Browser Access , respectively. Only the OIDC Variant gets an ingress. The others are connected to internally only. By Design, tokens cannot be used from outside the cluster by users. Outside-of-cluster traffic is only possible through OIDC. The Vault versions need the following configurations changes: Add to the MinIO Credential injector Add to the Goofys injector Add to the Kubeflow Controller (in the future, the profiles-controller). Grant Vault access by configuring the terraform for Vault which creates the necessary mounts and roles . At the moment this is done from within the terraform module that deploys these ArgoCD Application s.","title":"MinIO Gateway"},{"location":"storage-system/kustomize-gateway/#minio-gateway","text":"Each MinIO Gateway consists of MinIO + OPA + Etcd, with MinIO running in gateway mode, etcd acting as a cachefor the credentials, and OPA doing the policy enforcement. All except the OIDC flavour use Vault and the vault-minio-plugin for managing access/secret keys. There are four flavours of the gateway: Note: Only the OIDC version will have an Ingress. See notes below","title":"MinIO Gateway"},{"location":"storage-system/kustomize-gateway/#overlaysgateway-rw-read-write-vault-version","text":"This version is the stock version, with OPA configuration to allow users to both read and write from MinIO. Note: This system will not have an Ingress object. This will only be accessed by an internal URL, which prevents tokens from being used from outside the cluster.","title":"overlays/gateway-rw (Read-Write Vault Version)"},{"location":"storage-system/kustomize-gateway/#overlaysgateway-ro-read-only-vault-version","text":"This version is the stock version, with OPA configuration to only allow READ operations from users. The typical use-case here is to provide a read-only mirror of the data. For example, unclassified data can be made available as a read-only system to the protected-b notebooks, to allow use-cases like webscraping. Note: This system will not have an Ingress object. This will only be accessed by an internal URL, which prevents tokens from being used from outside the cluster.","title":"overlays/gateway-ro (Read-Only Vault Version)"},{"location":"storage-system/kustomize-gateway/#overlaysgateway-oidc-read-write-oidc-version","text":"This version does not use Vault, but instead uses the kubeflow-opa-sync to get RoleBindings in the namespace. A user can connect to a bucket over OIDC if their username is assigned a contributor role in the namespace.","title":"overlays/gateway-oidc (Read-Write OIDC Version)"},{"location":"storage-system/kustomize-gateway/#overlaysgateway-bundle-remotely-configured-vault-version","text":"The bundle version refers to OPA Bundles , the use case here is when we are providing access to data within the cluster, but the allowed users and rules around the data is not determined by us. In this case, we are working with the FAIR Data Infrastructure team, who is responsible for the data and governance over it.","title":"overlays/gateway-bundle (Remotely Configured Vault Version)"},{"location":"storage-system/kustomize-gateway/#architecture","text":"Most aspects of the architecture are captured in the diagram below (which pictures a Vault version plus and OIDC version). Note that each MinIO gateway instance resides in a different namespace, mostly to avoid name conflicts as well as to be able to apply network policies at the namespace level. Notable aspects of the design: All instances live in their own namespace. This is to simplify name conflicts and network policies Expected use is to use the data.statcan.gc.ca/classification label on the namespace to restrict connections. Only the minio-gateway:9000 service in the namespace should be reachable by notebooks. Vault needs access to all namespaces (except the OIDC setup). All need to be able to connect to Azure. Many systems share one storage account. A single \"tenant\" could have a readwrite , readonly , and oidc instance, to allow Unclassified Notebook Access , Protected-B Notebook Access , and Web-Browser Access , respectively. Only the OIDC Variant gets an ingress. The others are connected to internally only. By Design, tokens cannot be used from outside the cluster by users. Outside-of-cluster traffic is only possible through OIDC. The Vault versions need the following configurations changes: Add to the MinIO Credential injector Add to the Goofys injector Add to the Kubeflow Controller (in the future, the profiles-controller). Grant Vault access by configuring the terraform for Vault which creates the necessary mounts and roles . At the moment this is done from within the terraform module that deploys these ArgoCD Application s.","title":"Architecture"},{"location":"storage-system/kustomize-gateway/base/","text":"Notes & Warnings NOTE!!! Tolerations and nodeSelector are not respected from the values.yaml files. All tolerations are set to [] in the kustomization.yaml file. This is because we need the array to exist in order to apply subsequent Json6902 patches.","title":"Notes & Warnings"},{"location":"storage-system/kustomize-gateway/base/#notes-warnings","text":"NOTE!!! Tolerations and nodeSelector are not respected from the values.yaml files. All tolerations are set to [] in the kustomization.yaml file. This is because we need the array to exist in order to apply subsequent Json6902 patches.","title":"Notes &amp; Warnings"},{"location":"storage-system/kustomize-gateway/overlays/gateway-bundle/","text":"OPA Bundle Server This MinIO instance, unlike the others, uses a remote OPA configuration. It was created for the purpose of collaborating with the FAIR Data Infrastructure team (FAIR-DI), so that they could manage the access to datasets themselves and have MinIO pick up their configuration automatically. This setup requires an additional Storage Account to be created, in addition to the actual storage account used for the data. The second storage account stores bundles of rego and json.","title":"OPA Bundle Server"},{"location":"storage-system/kustomize-gateway/overlays/gateway-bundle/#opa-bundle-server","text":"This MinIO instance, unlike the others, uses a remote OPA configuration. It was created for the purpose of collaborating with the FAIR Data Infrastructure team (FAIR-DI), so that they could manage the access to datasets themselves and have MinIO pick up their configuration automatically. This setup requires an additional Storage Account to be created, in addition to the actual storage account used for the data. The second storage account stores bundles of rego and json.","title":"OPA Bundle Server"}]}